{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L3-ikINq_CDz"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import matplotlib.dates as mdates\n",
    "import re\n",
    "import os\n",
    "import datetime\n",
    "import plotly\n",
    "import warnings\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "# Offline mode\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "import plotly.io as pio\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YgmwH-BI_txh"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "InRp4djsBMwh",
    "outputId": "f74cb2fa-e518-4fcd-8fdb-55adf07eaaa9"
   },
   "outputs": [],
   "source": [
    "#!ls \"/content/drive/My Drive/Uni/Msc Comp Science/Year Two/Research/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PDpTvukh_lip"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1152x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set the global default size of matplotlib figures\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.rc('figure', figsize=(16,8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_dataframe_info(df):\n",
    "    print(df.shape)\n",
    "    print(list(df.columns.values))\n",
    "    print('\\n dataframe info: \\n', df.info())\n",
    "    print('\\n dataframe column datatypes:\\n', df.dtypes)\n",
    "\n",
    "#show_dataframe_info()\n",
    "\n",
    "def SetColor(x):\n",
    "    if isinstance(x, float):\n",
    "        if(x <= 12):\n",
    "            return \"green\"\n",
    "        elif(x > 12 and x <= 35.4):\n",
    "            return \"yellow\"\n",
    "        elif(x >35.4 and x <= 55.4 ):\n",
    "            return \"orange\"\n",
    "        elif(x >55.4 and x <= 150.4 ):\n",
    "            return \"red\"\n",
    "        elif(x > 150.4  and x <= 250.4 ):\n",
    "            return \"purple\"\n",
    "        elif(x > 250.4):\n",
    "            return \"maroon\"\n",
    "        #else:\n",
    "            #return \"black\"\n",
    "            \n",
    "def remove_special_characters(original_string):\n",
    "    cleaned_string = re.sub('[^A-Za-z0-9_-]+', '', original_string)\n",
    "    return cleaned_string\n",
    "\n",
    "def create_directory(folder_path):\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "        \n",
    "def make_simple_line_chart(x_axis_data,y_axis_data, x_axis_label,y_axis_label, chart_title, saved_fig_full_filepath='chart'):\n",
    "    fig = plt.figure(figsize=(24,12))\n",
    "    plt.rcParams.update({'font.size':14, 'font.weight':'bold'})\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.plot(x_axis_data, y_axis_data, color='blue', marker='o', linestyle='solid')\n",
    "    plt.title(chart_title, fontsize=20)\n",
    "    plt.ylabel(y_axis_label, fontsize=20)\n",
    "    plt.xlabel(x_axis_label,fontsize=20)\n",
    "    \n",
    "    hours = mdates.HourLocator(interval = 1)\n",
    "    hour_format = mdates.DateFormatter('%H:%M')\n",
    "    ax.xaxis.set_major_locator(hours)\n",
    "    ax.xaxis.set_major_formatter(hour_format)\n",
    "    \n",
    "      ##coloring\n",
    "    ax.axhspan(0, 12, facecolor='green')\n",
    "    ax.axhspan(12, 35.4, facecolor='yellow')\n",
    "    ax.axhspan(35.4, 55.4, facecolor='orange')\n",
    "    ax.axhspan(55.4, 150.4, facecolor='red')\n",
    "    ax.axhspan(150.4, 250.4, facecolor='purple')\n",
    "    ax.axhspan(250.4, 500.4, facecolor='maroon')\n",
    "    \n",
    "    plt.show()\n",
    "    fig.savefig(saved_fig_full_filepath + '.png')\n",
    "    \n",
    "    \n",
    "def  generate_dates(number_of_days_to_subtract_from_currentdate):\n",
    "    current_date = datetime.datetime.now()\n",
    "    specified_date = current_date - datetime.timedelta(days =number_of_days_to_subtract_from_currentdate)\n",
    "    return specified_date.strftime('%Y-%m-%d')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in greenness and airquality data for preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "SYFacJONAbXp",
    "outputId": "64f8dc9d-06fa-4a4a-edba-b03a81f1a885"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>entry_id</th>\n",
       "      <th>field1</th>\n",
       "      <th>field2</th>\n",
       "      <th>field3</th>\n",
       "      <th>field4</th>\n",
       "      <th>field5</th>\n",
       "      <th>field6</th>\n",
       "      <th>field7</th>\n",
       "      <th>field8</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevation</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-03-28 10:24:23 EAT</td>\n",
       "      <td>1</td>\n",
       "      <td>77.08</td>\n",
       "      <td>83.93</td>\n",
       "      <td>70.38</td>\n",
       "      <td>75.70</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.78</td>\n",
       "      <td>0.000000,0.000000,  0.00,0.00,0.00,0.00,26.00,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-03-28 10:25:41 EAT</td>\n",
       "      <td>2</td>\n",
       "      <td>80.48</td>\n",
       "      <td>87.35</td>\n",
       "      <td>70.43</td>\n",
       "      <td>75.57</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>3.83</td>\n",
       "      <td>1000.000000,1000.000000,1000000.00,-1.00,255.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-03-29 12:15:16 EAT</td>\n",
       "      <td>3</td>\n",
       "      <td>33.62</td>\n",
       "      <td>41.98</td>\n",
       "      <td>31.08</td>\n",
       "      <td>35.42</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.72</td>\n",
       "      <td>0.000000,0.000000,  0.00,0.00,0.00,0.00,32.00,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-03-29 12:16:34 EAT</td>\n",
       "      <td>4</td>\n",
       "      <td>29.87</td>\n",
       "      <td>34.98</td>\n",
       "      <td>31.13</td>\n",
       "      <td>34.20</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>3.93</td>\n",
       "      <td>1000.000000,1000.000000,1000000.00,-1.00,255.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-03-29 12:17:50 EAT</td>\n",
       "      <td>5</td>\n",
       "      <td>28.87</td>\n",
       "      <td>31.40</td>\n",
       "      <td>30.10</td>\n",
       "      <td>33.17</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>4.01</td>\n",
       "      <td>1000.000000,1000.000000,1000000.00,-1.00,255.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-03-29 12:19:07 EAT</td>\n",
       "      <td>6</td>\n",
       "      <td>38.63</td>\n",
       "      <td>46.82</td>\n",
       "      <td>39.02</td>\n",
       "      <td>46.07</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>4.02</td>\n",
       "      <td>1000.000000,1000.000000,1000000.00,-1.00,255.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-03-29 12:20:31 EAT</td>\n",
       "      <td>7</td>\n",
       "      <td>28.42</td>\n",
       "      <td>33.82</td>\n",
       "      <td>24.18</td>\n",
       "      <td>25.45</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>4.05</td>\n",
       "      <td>1000.000000,1000.000000,1000000.00,-1.00,255.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-03-29 12:21:48 EAT</td>\n",
       "      <td>8</td>\n",
       "      <td>45.83</td>\n",
       "      <td>56.00</td>\n",
       "      <td>42.35</td>\n",
       "      <td>50.23</td>\n",
       "      <td>0.297720</td>\n",
       "      <td>32.555157</td>\n",
       "      <td>4.06</td>\n",
       "      <td>0.297720,32.555157,1000000.00,0.44,255.00,4294...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-03-29 12:23:05 EAT</td>\n",
       "      <td>9</td>\n",
       "      <td>34.65</td>\n",
       "      <td>40.22</td>\n",
       "      <td>33.48</td>\n",
       "      <td>39.20</td>\n",
       "      <td>0.297720</td>\n",
       "      <td>32.555157</td>\n",
       "      <td>4.07</td>\n",
       "      <td>0.297720,32.555157,1205.70,0.44,4.00,451.00,34...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-03-29 12:24:21 EAT</td>\n",
       "      <td>10</td>\n",
       "      <td>39.28</td>\n",
       "      <td>47.67</td>\n",
       "      <td>31.68</td>\n",
       "      <td>36.53</td>\n",
       "      <td>0.297842</td>\n",
       "      <td>32.555035</td>\n",
       "      <td>4.07</td>\n",
       "      <td>0.297842,32.555035,1194.50,0.07,5.00,220.00,34...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                created_at  entry_id  field1  field2  field3  field4  \\\n",
       "0  2019-03-28 10:24:23 EAT         1   77.08   83.93   70.38   75.70   \n",
       "1  2019-03-28 10:25:41 EAT         2   80.48   87.35   70.43   75.57   \n",
       "2  2019-03-29 12:15:16 EAT         3   33.62   41.98   31.08   35.42   \n",
       "3  2019-03-29 12:16:34 EAT         4   29.87   34.98   31.13   34.20   \n",
       "4  2019-03-29 12:17:50 EAT         5   28.87   31.40   30.10   33.17   \n",
       "5  2019-03-29 12:19:07 EAT         6   38.63   46.82   39.02   46.07   \n",
       "6  2019-03-29 12:20:31 EAT         7   28.42   33.82   24.18   25.45   \n",
       "7  2019-03-29 12:21:48 EAT         8   45.83   56.00   42.35   50.23   \n",
       "8  2019-03-29 12:23:05 EAT         9   34.65   40.22   33.48   39.20   \n",
       "9  2019-03-29 12:24:21 EAT        10   39.28   47.67   31.68   36.53   \n",
       "\n",
       "        field5       field6  field7  \\\n",
       "0     0.000000     0.000000    3.78   \n",
       "1  1000.000000  1000.000000    3.83   \n",
       "2     0.000000     0.000000    3.72   \n",
       "3  1000.000000  1000.000000    3.93   \n",
       "4  1000.000000  1000.000000    4.01   \n",
       "5  1000.000000  1000.000000    4.02   \n",
       "6  1000.000000  1000.000000    4.05   \n",
       "7     0.297720    32.555157    4.06   \n",
       "8     0.297720    32.555157    4.07   \n",
       "9     0.297842    32.555035    4.07   \n",
       "\n",
       "                                              field8  latitude  longitude  \\\n",
       "0  0.000000,0.000000,  0.00,0.00,0.00,0.00,26.00,...       NaN        NaN   \n",
       "1  1000.000000,1000.000000,1000000.00,-1.00,255.0...       NaN        NaN   \n",
       "2  0.000000,0.000000,  0.00,0.00,0.00,0.00,32.00,...       NaN        NaN   \n",
       "3  1000.000000,1000.000000,1000000.00,-1.00,255.0...       NaN        NaN   \n",
       "4  1000.000000,1000.000000,1000000.00,-1.00,255.0...       NaN        NaN   \n",
       "5  1000.000000,1000.000000,1000000.00,-1.00,255.0...       NaN        NaN   \n",
       "6  1000.000000,1000.000000,1000000.00,-1.00,255.0...       NaN        NaN   \n",
       "7  0.297720,32.555157,1000000.00,0.44,255.00,4294...       NaN        NaN   \n",
       "8  0.297720,32.555157,1205.70,0.44,4.00,451.00,34...       NaN        NaN   \n",
       "9  0.297842,32.555035,1194.50,0.07,5.00,220.00,34...       NaN        NaN   \n",
       "\n",
       "   elevation  status  \n",
       "0        NaN     NaN  \n",
       "1        NaN     NaN  \n",
       "2        NaN     NaN  \n",
       "3        NaN     NaN  \n",
       "4        NaN     NaN  \n",
       "5        NaN     NaN  \n",
       "6        NaN     NaN  \n",
       "7        NaN     NaN  \n",
       "8        NaN     NaN  \n",
       "9        NaN     NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_data_dir = 'data'\n",
    "base_dir ='data\\AirQuality\\AirQo'\n",
    "vi_base_dir ='data\\Modis'\n",
    "\n",
    "#airquality_data = pd.read_csv(os.path.join(base_dir,'Jinja_Road(NEMAHOUSE)','nema.csv'))\n",
    "#vi_data = pd.read_csv(os.path.join(vi_base_dir,'jinja-road-nema-house-vi-2017-2019','jinja-road-nema-house-vi-2017-2019-MOD13A3-006-results.csv'))\n",
    "#filepath = os.path.join(base_dir,'Jinja_Road(NEMAHOUSE)')\n",
    "\n",
    "airquality_data = pd.read_csv(os.path.join(base_dir,'Rubaga_Kabusu','rubaga_kabusu.csv'))\n",
    "vi_dataa = pd.read_csv(os.path.join(vi_base_dir,'rubaga-kabusu-vi-2017-2019','rubaga-kabusu-vi-2017-2019-MOD13A3-006-results.csv'))\n",
    "filepath = os.path.join(base_dir,'Rubaga_Kabusu')\n",
    "\n",
    "#airquality_data = pd.read_csv(os.path.join(base_dir,'Kireka','kireka.csv'))\n",
    "#vi_dataa = pd.read_csv(os.path.join(vi_base_dir,'kireka-vi-2017-2019','kireka-vi-2017-2019-MOD13A3-006-results.csv'))\n",
    "#filepath = os.path.join(base_dir,'Kireka')\n",
    "\n",
    "airquality_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "airquality_data.rename(columns={'field1':'Sensor1 PM2.5_CF_1_ug/m3','field2':'Sensor1 PM10_CF_1_ug/m3',\n",
    "                                     'field3':'Sensor2PM2.5_CF_1_ug/m3', 'field4':'Sensor2 PM10_CF_1_ug/m3',\n",
    "                                     'field5': 'Latitude', 'field6':'Longitude', 'field7':'Battery Voltage', \n",
    "                                     'field8':'GpsData'},inplace=True)\n",
    "\n",
    "   \n",
    "airquality_data['PM2.5(Ug/m3) '] = airquality_data[['Sensor1 PM2.5_CF_1_ug/m3', 'Sensor2PM2.5_CF_1_ug/m3']].mean(axis=1)\n",
    "airquality_data['PM10(Ug/m3)'] = airquality_data[['Sensor1 PM10_CF_1_ug/m3', 'Sensor2 PM10_CF_1_ug/m3']].mean(axis=1)\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>entry_id</th>\n",
       "      <th>Sensor1 PM2.5_CF_1_ug/m3</th>\n",
       "      <th>Sensor1 PM10_CF_1_ug/m3</th>\n",
       "      <th>Sensor2PM2.5_CF_1_ug/m3</th>\n",
       "      <th>Sensor2 PM10_CF_1_ug/m3</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Battery Voltage</th>\n",
       "      <th>GpsData</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevation</th>\n",
       "      <th>status</th>\n",
       "      <th>PM2.5(Ug/m3)</th>\n",
       "      <th>PM10(Ug/m3)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-03-28 10:24:23 EAT</td>\n",
       "      <td>1</td>\n",
       "      <td>77.08</td>\n",
       "      <td>83.93</td>\n",
       "      <td>70.38</td>\n",
       "      <td>75.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.78</td>\n",
       "      <td>0.000000,0.000000,  0.00,0.00,0.00,0.00,26.00,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.730</td>\n",
       "      <td>79.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-03-28 10:25:41 EAT</td>\n",
       "      <td>2</td>\n",
       "      <td>80.48</td>\n",
       "      <td>87.35</td>\n",
       "      <td>70.43</td>\n",
       "      <td>75.57</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>3.83</td>\n",
       "      <td>1000.000000,1000.000000,1000000.00,-1.00,255.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.455</td>\n",
       "      <td>81.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-03-29 12:15:16 EAT</td>\n",
       "      <td>3</td>\n",
       "      <td>33.62</td>\n",
       "      <td>41.98</td>\n",
       "      <td>31.08</td>\n",
       "      <td>35.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.72</td>\n",
       "      <td>0.000000,0.000000,  0.00,0.00,0.00,0.00,32.00,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.350</td>\n",
       "      <td>38.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-03-29 12:16:34 EAT</td>\n",
       "      <td>4</td>\n",
       "      <td>29.87</td>\n",
       "      <td>34.98</td>\n",
       "      <td>31.13</td>\n",
       "      <td>34.20</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>3.93</td>\n",
       "      <td>1000.000000,1000.000000,1000000.00,-1.00,255.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.500</td>\n",
       "      <td>34.590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-03-29 12:17:50 EAT</td>\n",
       "      <td>5</td>\n",
       "      <td>28.87</td>\n",
       "      <td>31.40</td>\n",
       "      <td>30.10</td>\n",
       "      <td>33.17</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>4.01</td>\n",
       "      <td>1000.000000,1000.000000,1000000.00,-1.00,255.0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.485</td>\n",
       "      <td>32.285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                created_at  entry_id  Sensor1 PM2.5_CF_1_ug/m3  \\\n",
       "0  2019-03-28 10:24:23 EAT         1                     77.08   \n",
       "1  2019-03-28 10:25:41 EAT         2                     80.48   \n",
       "2  2019-03-29 12:15:16 EAT         3                     33.62   \n",
       "3  2019-03-29 12:16:34 EAT         4                     29.87   \n",
       "4  2019-03-29 12:17:50 EAT         5                     28.87   \n",
       "\n",
       "   Sensor1 PM10_CF_1_ug/m3  Sensor2PM2.5_CF_1_ug/m3  Sensor2 PM10_CF_1_ug/m3  \\\n",
       "0                    83.93                    70.38                    75.70   \n",
       "1                    87.35                    70.43                    75.57   \n",
       "2                    41.98                    31.08                    35.42   \n",
       "3                    34.98                    31.13                    34.20   \n",
       "4                    31.40                    30.10                    33.17   \n",
       "\n",
       "   Latitude  Longitude  Battery Voltage  \\\n",
       "0       0.0        0.0             3.78   \n",
       "1    1000.0     1000.0             3.83   \n",
       "2       0.0        0.0             3.72   \n",
       "3    1000.0     1000.0             3.93   \n",
       "4    1000.0     1000.0             4.01   \n",
       "\n",
       "                                             GpsData  latitude  longitude  \\\n",
       "0  0.000000,0.000000,  0.00,0.00,0.00,0.00,26.00,...       NaN        NaN   \n",
       "1  1000.000000,1000.000000,1000000.00,-1.00,255.0...       NaN        NaN   \n",
       "2  0.000000,0.000000,  0.00,0.00,0.00,0.00,32.00,...       NaN        NaN   \n",
       "3  1000.000000,1000.000000,1000000.00,-1.00,255.0...       NaN        NaN   \n",
       "4  1000.000000,1000.000000,1000000.00,-1.00,255.0...       NaN        NaN   \n",
       "\n",
       "   elevation  status  PM2.5(Ug/m3)   PM10(Ug/m3)  \n",
       "0        NaN     NaN         73.730       79.815  \n",
       "1        NaN     NaN         75.455       81.460  \n",
       "2        NaN     NaN         32.350       38.700  \n",
       "3        NaN     NaN         30.500       34.590  \n",
       "4        NaN     NaN         29.485       32.285  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airquality_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "Ho2ych4lB3cA",
    "outputId": "e9350cb4-7146-4295-cd8e-7060d0f7d821"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>entry_id</th>\n",
       "      <th>Sensor1 PM2.5_CF_1_ug/m3</th>\n",
       "      <th>Sensor1 PM10_CF_1_ug/m3</th>\n",
       "      <th>Sensor2PM2.5_CF_1_ug/m3</th>\n",
       "      <th>Sensor2 PM10_CF_1_ug/m3</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Battery Voltage</th>\n",
       "      <th>GpsData</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevation</th>\n",
       "      <th>status</th>\n",
       "      <th>PM2.5(Ug/m3)</th>\n",
       "      <th>PM10(Ug/m3)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63894</th>\n",
       "      <td>2019-05-30 10:26:35 EAT</td>\n",
       "      <td>63895</td>\n",
       "      <td>61.88</td>\n",
       "      <td>74.37</td>\n",
       "      <td>52.10</td>\n",
       "      <td>62.33</td>\n",
       "      <td>0.297929</td>\n",
       "      <td>32.554970</td>\n",
       "      <td>4.17</td>\n",
       "      <td>0.297929,32.554970,1226.40,0.19,9.00,84.00,30....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.990</td>\n",
       "      <td>68.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63895</th>\n",
       "      <td>2019-05-30 10:27:53 EAT</td>\n",
       "      <td>63896</td>\n",
       "      <td>60.10</td>\n",
       "      <td>72.77</td>\n",
       "      <td>51.02</td>\n",
       "      <td>62.20</td>\n",
       "      <td>0.297840</td>\n",
       "      <td>32.555004</td>\n",
       "      <td>4.18</td>\n",
       "      <td>0.297840,32.555004,1213.00,0.05,10.00,87.00,30...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.560</td>\n",
       "      <td>67.485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63896</th>\n",
       "      <td>2019-05-30 10:29:17 EAT</td>\n",
       "      <td>63897</td>\n",
       "      <td>45.72</td>\n",
       "      <td>58.37</td>\n",
       "      <td>40.78</td>\n",
       "      <td>48.15</td>\n",
       "      <td>0.297822</td>\n",
       "      <td>32.555012</td>\n",
       "      <td>4.17</td>\n",
       "      <td>0.297822,32.555012,1212.20,0.11,9.00,100.00,30...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.250</td>\n",
       "      <td>53.260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63897</th>\n",
       "      <td>2019-05-30 10:30:28 EAT</td>\n",
       "      <td>63898</td>\n",
       "      <td>35.57</td>\n",
       "      <td>41.85</td>\n",
       "      <td>37.78</td>\n",
       "      <td>42.93</td>\n",
       "      <td>0.297911</td>\n",
       "      <td>32.554955</td>\n",
       "      <td>4.18</td>\n",
       "      <td>0.297911,32.554955,1225.30,0.20,10.00,127.00,3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.675</td>\n",
       "      <td>42.390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63898</th>\n",
       "      <td>2019-05-30 10:31:54 EAT</td>\n",
       "      <td>63899</td>\n",
       "      <td>39.07</td>\n",
       "      <td>49.55</td>\n",
       "      <td>35.78</td>\n",
       "      <td>41.60</td>\n",
       "      <td>0.297892</td>\n",
       "      <td>32.555019</td>\n",
       "      <td>4.18</td>\n",
       "      <td>0.297892,32.555019,1223.60,0.21,8.00,96.00,31....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.425</td>\n",
       "      <td>45.575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    created_at  entry_id  Sensor1 PM2.5_CF_1_ug/m3  \\\n",
       "63894  2019-05-30 10:26:35 EAT     63895                     61.88   \n",
       "63895  2019-05-30 10:27:53 EAT     63896                     60.10   \n",
       "63896  2019-05-30 10:29:17 EAT     63897                     45.72   \n",
       "63897  2019-05-30 10:30:28 EAT     63898                     35.57   \n",
       "63898  2019-05-30 10:31:54 EAT     63899                     39.07   \n",
       "\n",
       "       Sensor1 PM10_CF_1_ug/m3  Sensor2PM2.5_CF_1_ug/m3  \\\n",
       "63894                    74.37                    52.10   \n",
       "63895                    72.77                    51.02   \n",
       "63896                    58.37                    40.78   \n",
       "63897                    41.85                    37.78   \n",
       "63898                    49.55                    35.78   \n",
       "\n",
       "       Sensor2 PM10_CF_1_ug/m3  Latitude  Longitude  Battery Voltage  \\\n",
       "63894                    62.33  0.297929  32.554970             4.17   \n",
       "63895                    62.20  0.297840  32.555004             4.18   \n",
       "63896                    48.15  0.297822  32.555012             4.17   \n",
       "63897                    42.93  0.297911  32.554955             4.18   \n",
       "63898                    41.60  0.297892  32.555019             4.18   \n",
       "\n",
       "                                                 GpsData  latitude  longitude  \\\n",
       "63894  0.297929,32.554970,1226.40,0.19,9.00,84.00,30....       NaN        NaN   \n",
       "63895  0.297840,32.555004,1213.00,0.05,10.00,87.00,30...       NaN        NaN   \n",
       "63896  0.297822,32.555012,1212.20,0.11,9.00,100.00,30...       NaN        NaN   \n",
       "63897  0.297911,32.554955,1225.30,0.20,10.00,127.00,3...       NaN        NaN   \n",
       "63898  0.297892,32.555019,1223.60,0.21,8.00,96.00,31....       NaN        NaN   \n",
       "\n",
       "       elevation  status  PM2.5(Ug/m3)   PM10(Ug/m3)  \n",
       "63894        NaN     NaN         56.990       68.350  \n",
       "63895        NaN     NaN         55.560       67.485  \n",
       "63896        NaN     NaN         43.250       53.260  \n",
       "63897        NaN     NaN         36.675       42.390  \n",
       "63898        NaN     NaN         37.425       45.575  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airquality_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "LueXKLM3B_DR",
    "outputId": "e78ead69-4cb9-4174-b719-4a62f71cd448"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63899, 16)\n",
      "['created_at', 'entry_id', 'Sensor1 PM2.5_CF_1_ug/m3', 'Sensor1 PM10_CF_1_ug/m3', 'Sensor2PM2.5_CF_1_ug/m3', 'Sensor2 PM10_CF_1_ug/m3', 'Latitude', 'Longitude', 'Battery Voltage', 'GpsData', 'latitude', 'longitude', 'elevation', 'status', 'PM2.5(Ug/m3) ', 'PM10(Ug/m3)']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 63899 entries, 0 to 63898\n",
      "Data columns (total 16 columns):\n",
      "created_at                  63899 non-null object\n",
      "entry_id                    63899 non-null int64\n",
      "Sensor1 PM2.5_CF_1_ug/m3    63899 non-null float64\n",
      "Sensor1 PM10_CF_1_ug/m3     63899 non-null float64\n",
      "Sensor2PM2.5_CF_1_ug/m3     63899 non-null float64\n",
      "Sensor2 PM10_CF_1_ug/m3     63899 non-null float64\n",
      "Latitude                    63899 non-null float64\n",
      "Longitude                   63899 non-null float64\n",
      "Battery Voltage             63899 non-null float64\n",
      "GpsData                     63899 non-null object\n",
      "latitude                    0 non-null float64\n",
      "longitude                   0 non-null float64\n",
      "elevation                   0 non-null float64\n",
      "status                      0 non-null float64\n",
      "PM2.5(Ug/m3)                63899 non-null float64\n",
      "PM10(Ug/m3)                 63899 non-null float64\n",
      "dtypes: float64(13), int64(1), object(2)\n",
      "memory usage: 7.8+ MB\n",
      "\n",
      " dataframe info: \n",
      " None\n",
      "\n",
      " dataframe column datatypes:\n",
      " created_at                   object\n",
      "entry_id                      int64\n",
      "Sensor1 PM2.5_CF_1_ug/m3    float64\n",
      "Sensor1 PM10_CF_1_ug/m3     float64\n",
      "Sensor2PM2.5_CF_1_ug/m3     float64\n",
      "Sensor2 PM10_CF_1_ug/m3     float64\n",
      "Latitude                    float64\n",
      "Longitude                   float64\n",
      "Battery Voltage             float64\n",
      "GpsData                      object\n",
      "latitude                    float64\n",
      "longitude                   float64\n",
      "elevation                   float64\n",
      "status                      float64\n",
      "PM2.5(Ug/m3)                float64\n",
      "PM10(Ug/m3)                 float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "show_dataframe_info(airquality_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "6inajEGHCWNw",
    "outputId": "e1592d77-e66b-4308-f9b7-494b93ec0a6c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entry_id</th>\n",
       "      <th>Sensor1 PM2.5_CF_1_ug/m3</th>\n",
       "      <th>Sensor1 PM10_CF_1_ug/m3</th>\n",
       "      <th>Sensor2PM2.5_CF_1_ug/m3</th>\n",
       "      <th>Sensor2 PM10_CF_1_ug/m3</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Battery Voltage</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevation</th>\n",
       "      <th>status</th>\n",
       "      <th>PM2.5(Ug/m3)</th>\n",
       "      <th>PM10(Ug/m3)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>63899.000000</td>\n",
       "      <td>63899.000000</td>\n",
       "      <td>63899.000000</td>\n",
       "      <td>63899.000000</td>\n",
       "      <td>63899.000000</td>\n",
       "      <td>63899.000000</td>\n",
       "      <td>63899.000000</td>\n",
       "      <td>63899.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63899.000000</td>\n",
       "      <td>63899.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>31950.000000</td>\n",
       "      <td>52.447959</td>\n",
       "      <td>63.092592</td>\n",
       "      <td>49.585554</td>\n",
       "      <td>55.802232</td>\n",
       "      <td>0.610745</td>\n",
       "      <td>32.854724</td>\n",
       "      <td>4.158654</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.016757</td>\n",
       "      <td>59.447412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18446.196762</td>\n",
       "      <td>45.324713</td>\n",
       "      <td>53.212623</td>\n",
       "      <td>41.234693</td>\n",
       "      <td>43.060099</td>\n",
       "      <td>17.683736</td>\n",
       "      <td>17.116100</td>\n",
       "      <td>0.075546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.085772</td>\n",
       "      <td>47.984041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>4.480000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.030000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.090000</td>\n",
       "      <td>3.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15975.500000</td>\n",
       "      <td>29.570000</td>\n",
       "      <td>35.420000</td>\n",
       "      <td>30.070000</td>\n",
       "      <td>33.550000</td>\n",
       "      <td>0.297842</td>\n",
       "      <td>32.554947</td>\n",
       "      <td>4.160000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.787500</td>\n",
       "      <td>34.495000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31950.000000</td>\n",
       "      <td>42.280000</td>\n",
       "      <td>53.970000</td>\n",
       "      <td>41.130000</td>\n",
       "      <td>48.950000</td>\n",
       "      <td>0.297869</td>\n",
       "      <td>32.554981</td>\n",
       "      <td>4.170000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.725000</td>\n",
       "      <td>51.460000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47924.500000</td>\n",
       "      <td>60.230000</td>\n",
       "      <td>73.770000</td>\n",
       "      <td>55.620000</td>\n",
       "      <td>65.530000</td>\n",
       "      <td>0.297898</td>\n",
       "      <td>32.555008</td>\n",
       "      <td>4.180000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.842500</td>\n",
       "      <td>69.617500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>63899.000000</td>\n",
       "      <td>971.630000</td>\n",
       "      <td>2021.000000</td>\n",
       "      <td>1198.200000</td>\n",
       "      <td>1402.630000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>4.190000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1084.915000</td>\n",
       "      <td>1610.035000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           entry_id  Sensor1 PM2.5_CF_1_ug/m3  Sensor1 PM10_CF_1_ug/m3  \\\n",
       "count  63899.000000              63899.000000             63899.000000   \n",
       "mean   31950.000000                 52.447959                63.092592   \n",
       "std    18446.196762                 45.324713                53.212623   \n",
       "min        1.000000                  0.480000                 0.850000   \n",
       "25%    15975.500000                 29.570000                35.420000   \n",
       "50%    31950.000000                 42.280000                53.970000   \n",
       "75%    47924.500000                 60.230000                73.770000   \n",
       "max    63899.000000                971.630000              2021.000000   \n",
       "\n",
       "       Sensor2PM2.5_CF_1_ug/m3  Sensor2 PM10_CF_1_ug/m3      Latitude  \\\n",
       "count             63899.000000             63899.000000  63899.000000   \n",
       "mean                 49.585554                55.802232      0.610745   \n",
       "std                  41.234693                43.060099     17.683736   \n",
       "min                   4.250000                 4.480000      0.000000   \n",
       "25%                  30.070000                33.550000      0.297842   \n",
       "50%                  41.130000                48.950000      0.297869   \n",
       "75%                  55.620000                65.530000      0.297898   \n",
       "max                1198.200000              1402.630000   1000.000000   \n",
       "\n",
       "          Longitude  Battery Voltage  latitude  longitude  elevation  status  \\\n",
       "count  63899.000000     63899.000000       0.0        0.0        0.0     0.0   \n",
       "mean      32.854724         4.158654       NaN        NaN        NaN     NaN   \n",
       "std       17.116100         0.075546       NaN        NaN        NaN     NaN   \n",
       "min        0.000000         3.030000       NaN        NaN        NaN     NaN   \n",
       "25%       32.554947         4.160000       NaN        NaN        NaN     NaN   \n",
       "50%       32.554981         4.170000       NaN        NaN        NaN     NaN   \n",
       "75%       32.555008         4.180000       NaN        NaN        NaN     NaN   \n",
       "max     1000.000000         4.190000       NaN        NaN        NaN     NaN   \n",
       "\n",
       "       PM2.5(Ug/m3)    PM10(Ug/m3)  \n",
       "count   63899.000000  63899.000000  \n",
       "mean       51.016757     59.447412  \n",
       "std        43.085772     47.984041  \n",
       "min         3.090000      3.300000  \n",
       "25%        29.787500     34.495000  \n",
       "50%        41.725000     51.460000  \n",
       "75%        57.842500     69.617500  \n",
       "max      1084.915000   1610.035000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airquality_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c0coWQUnDdxh"
   },
   "source": [
    "Now that we have a general idea of the data set contents, we can dive deeper into each column. We'll be doing exploratory data analysis and cleaning data to setup 'features' we'll be using in our machine learning and deeplearning algorithms.\n",
    "\n",
    "Plot a few features to get a better idea of each:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop columns that shall not be used during analysis\n",
    "- entry_id\n",
    "- Battery Voltage\n",
    "- Latitiude\n",
    "- Longitude\n",
    "- latitude\n",
    "- longitude\n",
    "- elevation\n",
    "- status\n",
    "- GpsData\n",
    "- Sensor1 PM2.5_CF_1_ug/m3\n",
    "- Sensor1 PM10_CF_1_ug/m3\n",
    "- Sensor2PM2.5_CF_1_ug/m3'\n",
    "- Sensor2 PM10_CF_1_ug/m3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "airquality_data_of_interest = airquality_data.drop(['entry_id','Latitude', 'Longitude', 'Battery Voltage',\n",
    "                                                    'latitude','longitude','elevation','status','GpsData',\n",
    "                                                    'Sensor1 PM2.5_CF_1_ug/m3','Sensor1 PM10_CF_1_ug/m3',\n",
    "                                                     'Sensor2PM2.5_CF_1_ug/m3','Sensor2 PM10_CF_1_ug/m3'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63899, 3)\n",
      "['created_at', 'PM2.5(Ug/m3) ', 'PM10(Ug/m3)']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 63899 entries, 0 to 63898\n",
      "Data columns (total 3 columns):\n",
      "created_at       63899 non-null object\n",
      "PM2.5(Ug/m3)     63899 non-null float64\n",
      "PM10(Ug/m3)      63899 non-null float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 1.5+ MB\n",
      "\n",
      " dataframe info: \n",
      " None\n",
      "\n",
      " dataframe column datatypes:\n",
      " created_at        object\n",
      "PM2.5(Ug/m3)     float64\n",
      "PM10(Ug/m3)      float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "airquality_data_of_interest.shape\n",
    "show_dataframe_info(airquality_data_of_interest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert data into timeseries dataframe with datetime being the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\envs\\airquality_prediction\\lib\\site-packages\\dateutil\\parser\\_parser.py:1204: UnknownTimezoneWarning:\n",
      "\n",
      "tzname EAT identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-03-28 10:24:23 EAT\n"
     ]
    }
   ],
   "source": [
    "#parsing the created_at field into a datetime object\n",
    "airquality_data_of_interest[\"TimeStamp\"] = pd.to_datetime(airquality_data_of_interest[\"created_at\"])\n",
    "\n",
    "is_utc_date = airquality_data_of_interest['created_at'].loc[0]\n",
    "print(is_utc_date)\n",
    "\n",
    "if \"UTC\" in is_utc_date:\n",
    "    print('utc found')\n",
    "    airquality_data_of_interest[\"TimeStamp\"] = airquality_data_of_interest[\"TimeStamp\"]+ datetime.timedelta(hours=3)\n",
    "\n",
    "    \n",
    "time_indexed_data = airquality_data_of_interest.set_index('TimeStamp')\n",
    "time_indexed_data = time_indexed_data.drop(['created_at'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PM2.5(Ug/m3)</th>\n",
       "      <th>PM10(Ug/m3)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TimeStamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-03-28 10:24:23</th>\n",
       "      <td>73.730</td>\n",
       "      <td>79.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-28 10:25:41</th>\n",
       "      <td>75.455</td>\n",
       "      <td>81.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-29 12:15:16</th>\n",
       "      <td>32.350</td>\n",
       "      <td>38.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-29 12:16:34</th>\n",
       "      <td>30.500</td>\n",
       "      <td>34.590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-29 12:17:50</th>\n",
       "      <td>29.485</td>\n",
       "      <td>32.285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     PM2.5(Ug/m3)   PM10(Ug/m3)\n",
       "TimeStamp                                      \n",
       "2019-03-28 10:24:23         73.730       79.815\n",
       "2019-03-28 10:25:41         75.455       81.460\n",
       "2019-03-29 12:15:16         32.350       38.700\n",
       "2019-03-29 12:16:34         30.500       34.590\n",
       "2019-03-29 12:17:50         29.485       32.285"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_indexed_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out outliers and remain with records with pm2.5 less than 500.4 and records with pm2.5 values  greater than zero "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'PM2.5(Ug/m3)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\airquality_prediction\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3077\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3078\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3079\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'PM2.5(Ug/m3)'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-de5aa836e9c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtime_indexed_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime_indexed_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtime_indexed_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'PM2.5(Ug/m3)'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m500.4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtime_indexed_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime_indexed_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtime_indexed_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'PM2.5(Ug/m3)'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime_indexed_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtime_indexed_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtime_indexed_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\airquality_prediction\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2686\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2687\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2688\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2690\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\airquality_prediction\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2693\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2694\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2695\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2697\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\airquality_prediction\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2488\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2489\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\airquality_prediction\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   4113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4114\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4115\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4116\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\airquality_prediction\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3078\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'PM2.5(Ug/m3)'"
     ]
    }
   ],
   "source": [
    "time_indexed_data = time_indexed_data[time_indexed_data['PM2.5(Ug/m3)'] <= 500.4]\n",
    "time_indexed_data = time_indexed_data[time_indexed_data['PM2.5(Ug/m3)'] > 0]\n",
    "print(time_indexed_data.shape)\n",
    "time_indexed_data.max()\n",
    "time_indexed_data.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the entire dataset pm2.5 timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = time_indexed_data['PM2.5(Ug/m3)'].values\n",
    "pm25 = go.Scatter(x=time_indexed_data.index,\n",
    "                         y = time_indexed_data['PM2.5(Ug/m3)'].values\n",
    "                 ) \n",
    "\n",
    "layout = go.Layout(title='PM2.5 Concentration ', xaxis=dict(title='Date'),\n",
    "                   yaxis=dict(title='PM2.5 Concentration(ug/m3)'))\n",
    "\n",
    "fig = go.Figure(data=[pm25], layout=layout)\n",
    "iplot(fig)\n",
    "pio.write_image(fig, os.path.join(filepath , 'pm25_concentration_timeseries.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute average hourly, daily, monthly concentration values (mean of the concentrations for each hour)\n",
    "- parse the created_at column into datetime.\n",
    "- set the created_at column to be the index for the dataframe.\n",
    "- calculate the corresponding means for hourly, daily and monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_average_airquality_data_concentrations = time_indexed_data.resample('H').mean().round(2) \n",
    "hourly_maximum_airquality_data_concentrations  = time_indexed_data.resample('H').max().round(2)\n",
    "hourly_minimum_airquality_data_concentrations  = time_indexed_data.resample('H').min().round(2)\n",
    "\n",
    "daily_average_airquality_data_concentrations  = time_indexed_data.resample('D').mean().round(2)\n",
    "daily_maximum_airquality_data_concentrations  = time_indexed_data.resample('D').max().round(2)\n",
    "daily_minimum_airquality_data_concentrations  = time_indexed_data.resample('D').min().round(2)\n",
    "\n",
    "monthly_average_airquality_data_concentrations  = time_indexed_data.resample('M').mean().round(2)\n",
    "\n",
    "\n",
    "hourly_average_airquality_data_concentrations.head()\n",
    "\n",
    "#drop nans\n",
    "monthly_average_airquality_data_concentrations_analysis= monthly_average_airquality_data_concentrations.dropna(axis=0)\n",
    "hourly_average_airquality_data_concentrations_analysis  = hourly_average_airquality_data_concentrations.dropna(axis=0)\n",
    "daily_average_airquality_data_concentrations_analysis  =  daily_average_airquality_data_concentrations.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_average_airquality_data_concentrations"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "all_data_05_09_data = time_indexed_data['2019-05-09 00:00:00':'2019-05-15 23:59:00']\n",
    "all_data_05_09_data.head()\n",
    "data_daily_average_airquality_data_concentrations_05_09_2019  = all_data_05_09_data.resample('D').mean().round(2)\n",
    "all_data_05_09_data.to_csv(os.path.join(filepath , 'all_pm25_concentration_09_05_2019.csv'))\n",
    "data_daily_average_airquality_data_concentrations_05_09_2019.to_csv(os.path.join(filepath , 'daily_average_pm25_concentration_09_05_2019.csv'))\n",
    "\n",
    "data_hourly_average_airquality_data_concentrations_05_09_2019  = all_data_05_09_data.resample('H').mean().round(2)\n",
    "data_hourly_average_airquality_data_concentrations_05_09_2019.to_csv(os.path.join(filepath , 'hourly_average_pm_concentration_09_05_2019_15_05_2019.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(daily_average_airquality_data_concentrations.size)\n",
    "daily_average_missing_airquality_data = daily_average_airquality_data_concentrations[daily_average_airquality_data_concentrations.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display information related to dataframe  after 24-hr-average(daily) and monthly average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_dataframe_info(daily_average_airquality_data_concentrations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_average_airquality_data_concentrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_dataframe_info(daily_average_airquality_data_concentrations)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "daily_average_airquality_data_concentrations.to_csv(os.path.join(filepath , 'daily_average_pm25_concentration.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_dataframe_info(monthly_average_airquality_data_concentrations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_average_airquality_data_concentrations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filling in the missing values with the average of the value after and before "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_average_airquality_data_concentrations = monthly_average_airquality_data_concentrations.where(monthly_average_airquality_data_concentrations.notnull(), other=(monthly_average_airquality_data_concentrations.fillna(method='ffill')+monthly_average_airquality_data_concentrations.fillna(method='bfill'))/2)\n",
    "daily_average_airquality_data_concentrations = daily_average_airquality_data_concentrations.where(daily_average_airquality_data_concentrations.notnull(), other=(daily_average_airquality_data_concentrations.fillna(method='ffill')+daily_average_airquality_data_concentrations.fillna(method='bfill'))/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the daily  pm2.5 concentration timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(daily_average_airquality_data_concentrations['PM2.5(Ug/m3)'].size)\n",
    "y = daily_average_airquality_data_concentrations['PM2.5(Ug/m3)'].dropna().values\n",
    "print(y.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##remove nan for visualizations \n",
    "y = daily_average_airquality_data_concentrations['PM2.5(Ug/m3)'].dropna().values\n",
    "pm25 = go.Scatter(x=daily_average_airquality_data_concentrations.dropna().index,\n",
    "                  y = daily_average_airquality_data_concentrations['PM2.5(Ug/m3)'].dropna().values, \n",
    "                  mode='markers',\n",
    "                  marker = dict(color=list(map(SetColor, y)),size=15)\n",
    "                  \n",
    "                 ) \n",
    "\n",
    "layout = go.Layout(title='Daily Average PM2.5 Concentration', xaxis=dict(title='Date'),\n",
    "                   yaxis=dict(title='PM2.5 Concentration(ug/m3)'))\n",
    "\n",
    "fig = go.Figure(data=[pm25], layout=layout)\n",
    "iplot(fig)\n",
    "pio.write_image(fig, os.path.join(filepath , 'daily_average_pm25_concentration.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "average_daily_pm25 = go.Scatter(x=daily_average_airquality_data_concentrations['PM2.5(Ug/m3)'].dropna().index,\n",
    "                         y = daily_average_airquality_data_concentrations['PM2.5(Ug/m3)'].dropna().values,\n",
    "                         #mode='lines+markers',\n",
    "                         #marker = dict(color=list(map(SetColor, y_average)), size = 17),\n",
    "                         name='Average Daily PM2.5 Concentration'\n",
    "                         #hoverinfo = 'text',\n",
    "                         #text=[f'PM2.5 Concentration: {x:.2f} ug/m3' for x in daily_average_airquality_data_concentrations['PM2.5(Ug/m3)']]\n",
    "                 )\n",
    "\n",
    "layout = go.Layout(title='Daily PM2.5 Concentration', xaxis=dict(title='Date'),\n",
    "                   yaxis=dict(title='PM2.5 Concentration(ug/m3)'))\n",
    "\n",
    "fig = go.Figure(data=[average_daily_pm25], layout=layout)\n",
    "iplot(fig)\n",
    "pio.write_image(fig, os.path.join(filepath , 'daily_average_pm25_concentration_trend.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the monthly pm2.5 concentration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "average_monthly_pm25 = monthly_average_airquality_data_concentrations['PM2.5(Ug/m3)'].values\n",
    "monthly_pm25 = go.Scatter(x=monthly_average_airquality_data_concentrations.index,\n",
    "                         y = monthly_average_airquality_data_concentrations['PM2.5(Ug/m3)'].values,\n",
    "                         mode='lines+markers',\n",
    "                         marker = dict(color=list(map(SetColor, average_monthly_pm25)), size = 17),\n",
    "                 ) \n",
    "\n",
    "layout = go.Layout(title='Monthly Average PM2.5 ', xaxis=dict(title='Date(UTC)'),\n",
    "                   yaxis=dict(title='PM2.5 Concentration(ug/m3)'))\n",
    "\n",
    "fig = go.Figure(data=[monthly_pm25], layout=layout)\n",
    "iplot(fig)\n",
    "pio.write_image(fig, os.path.join(filepath , 'monthly_average_pm25_concentration.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "monthly_pm25_trend = go.Scatter(x=monthly_average_airquality_data_concentrations.index,\n",
    "                         y = monthly_average_airquality_data_concentrations['PM2.5(Ug/m3)'].values,\n",
    "                         #mode='lines+markers',\n",
    "                        #marker = dict(color=list(map(SetColor, average_monthly_pm25)), size = 17),\n",
    "                 ) \n",
    "\n",
    "layout = go.Layout(title='Monthly Average PM2.5 ', xaxis=dict(title='Date(UTC)'),\n",
    "                   yaxis=dict(title='PM2.5 Concentration(ug/m3)'))\n",
    "\n",
    "fig = go.Figure(data=[monthly_pm25_trend], layout=layout)\n",
    "iplot(fig)\n",
    "pio.write_image(fig, os.path.join(filepath , 'monthly_average_pm25_concentration_trend.png'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the concentrations\n",
    "- hourly pm2.5\n",
    "- daily  pm2.5\n",
    "- monthly pm2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the hourly pm2.5 concentration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_dataframe_info(hourly_average_airquality_data_concentrations)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hourly_average_airquality_data_concentrations = hourly_average_airquality_data_concentrations.where(hourly_average_airquality_data_concentrations.notnull(), other=(hourly_average_airquality_data_concentrations.fillna(method='ffill')+hourly_average_airquality_data_concentrations.fillna(method='bfill'))/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hourly_airquality_data_concentrations['PM2.5(Ug/m3)'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hourly_pm25_trend = go.Scatter(x=hourly_average_airquality_data_concentrations.dropna().index,\n",
    "                         y = hourly_average_airquality_data_concentrations['PM2.5(Ug/m3)'].dropna().values,\n",
    "                 ) \n",
    "\n",
    "layout = go.Layout(title='Hourly Average PM2.5', xaxis=dict(title='Date'),\n",
    "                   yaxis=dict(title='PM2.5 Concentration(ug/m3)'))\n",
    "\n",
    "fig = go.Figure(data=[hourly_pm25_trend], layout=layout)\n",
    "iplot(fig)\n",
    "pio.write_image(fig,os.path.join(filepath , 'hourly_average_pm25_concentration_trend.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_dataframe_info(hourly_average_airquality_data_concentrations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_average_airquality_data_concentrations['hour'] = hourly_average_airquality_data_concentrations.index.hour\n",
    "hourly_average_airquality_data_concentrations['Hour']= pd.to_timedelta(hourly_average_airquality_data_concentrations['hour'],unit='h')\n",
    "\n",
    "hourly_average_airquality_data_concentrations_analysis['hour'] = hourly_average_airquality_data_concentrations_analysis.index.hour\n",
    "hourly_average_airquality_data_concentrations_analysis['Hour']= pd.to_timedelta(hourly_average_airquality_data_concentrations_analysis['hour'],unit='h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = generate_dates(0)\n",
    "current_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_dataframe_info(hourly_average_airquality_data_concentrations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fill the missing hours with the average of the hours through the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['PM2.5(Ug/m3)','PM10(Ug/m3)']\n",
    "original_hourly_data = hourly_average_airquality_data_concentrations.copy()\n",
    "hourly_average_airquality_data_concentrations[cols] = hourly_average_airquality_data_concentrations[cols].fillna(hourly_average_airquality_data_concentrations.groupby(hourly_average_airquality_data_concentrations['Hour'])[cols].transform('mean').round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_hourly_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_average_airquality_data_concentrations.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_pm25_concentration_for_each_hour_of_day = hourly_average_airquality_data_concentrations_analysis.groupby(['Hour']).mean().round(2) #.groups.keys()\n",
    "average_pm25_concentration_for_each_hour_of_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = datetime.datetime.now()\n",
    "average_pm25_concentration_for_each_hour_of_day['Date'] = pd.to_datetime(current_date.strftime('%Y-%m-%d')) \n",
    "average_pm25_concentration_for_each_hour_of_day['Time(hrs)']= average_pm25_concentration_for_each_hour_of_day.index\n",
    "average_pm25_concentration_for_each_hour_of_day['Time(hrs)']\n",
    "average_pm25_concentration_for_each_hour_of_day[['Date','Time(hrs)']].dtypes\n",
    "average_pm25_concentration_for_each_hour_of_day['TimeStamp']  = average_pm25_concentration_for_each_hour_of_day['Date']+ average_pm25_concentration_for_each_hour_of_day['Time(hrs)']\n",
    "average_pm25_concentration_for_each_hour_of_day.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the average of pm2.5 for each hour in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_axis_values = average_pm25_concentration_for_each_hour_of_day['PM2.5(Ug/m3)'].values\n",
    "x_axis_values = average_pm25_concentration_for_each_hour_of_day['TimeStamp'].values\n",
    "x_axis_label = 'Time(Hours)'\n",
    "y_axis_label =  'PM2.5 Concentration(ug/m3)'\n",
    "chart_title  =  'Average PM2.5 foreach Hour'\n",
    "file_path    =   os.path.join(filepath , 'average_pm25_foreach_hour')\n",
    "\n",
    "make_simple_line_chart(x_axis_values, y_axis_values, x_axis_label, y_axis_label, chart_title ,file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_pm25_trend_for_each_hour = go.Scatter(x=average_pm25_concentration_for_each_hour_of_day['TimeStamp'].values,\n",
    "                         y = average_pm25_concentration_for_each_hour_of_day['PM2.5(Ug/m3)'].values) \n",
    "\n",
    "layout = go.Layout(title='Average PM2.5 foreach Hour', xaxis=dict(title='Hour'),\n",
    "                   yaxis=dict(title='PM2.5 Concentration(ug/m3)'))\n",
    "\n",
    "fig = go.Figure(data=[average_pm25_trend_for_each_hour], layout=layout)\n",
    "iplot(fig)\n",
    "pio.write_image(fig, os.path.join(filepath , 'average_pm25_concentration_trend_for_each_hour.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the resampled pm2.5 concentration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_average_airquality_data_concentrations.to_csv(os.path.join(filepath , 'daily_average_pm25_concentration.csv'))\n",
    "monthly_average_airquality_data_concentrations.to_csv(os.path.join(filepath , 'monthly_average_pm25_concentration.csv'))\n",
    "hourly_average_airquality_data_concentrations.to_csv(os.path.join(filepath , 'hourly_average_pm25_concentration.csv'))\n",
    "average_pm25_concentration_for_each_hour_of_day.to_csv(os.path.join(filepath , 'average_pm25_concentration_for_each_hour_of_day.csv'))\n",
    "\n",
    "daily_average_airquality_data_concentrations_analysis.to_csv(os.path.join(filepath , 'daily_average_pm25_concentration_analysis.csv'))\n",
    "monthly_average_airquality_data_concentrations_analysis.to_csv(os.path.join(filepath , 'monthly_average_pm25_concentration_analysis.csv'))\n",
    "hourly_average_airquality_data_concentrations_analysis.to_csv(os.path.join(filepath , 'hourly_average_pm25_concentration_analysis.csv'))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "colab_type": "code",
    "id": "UAt5Y128DlYp",
    "outputId": "88703eba-d24a-471e-c772-b5b4ae40a8b0"
   },
   "source": [
    "# Set up a grid of plots\n",
    "fig = plt.figure(figsize=(16,8)) \n",
    "\n",
    "# Plot the PM2.5 histogram\n",
    "hourly_average_airquality_data_concentrations.hist()\n",
    "plt.title('PM2.5 Histogram \\n')\n",
    "#plt.xlabel('')\n",
    "#plt.ylabel('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analysis daily  airquality dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_dataframe_info(daily_average_airquality_data_concentrations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Histogram Distributions for the concentrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "colab_type": "code",
    "id": "P3JWybYka_az",
    "outputId": "3079cb25-972e-4543-93bc-f16d3923a14b"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "daily_average_airquality_data_concentrations.hist()\n",
    "plt.savefig(os.path.join(filepath ,\"daily_average_airquality_data_concentrations_historgram.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_average_airquality_data_concentrations.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_average_airquality_data_concentrations.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#daily_airquality_data_concentrations.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the daily airquality data concentrations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = daily_average_airquality_data_concentrations.values\n",
    "# specify columns to plot\n",
    "groups = [0,1,2]\n",
    "i = 1\n",
    "# plot each column\n",
    "\n",
    "plt.figure()\n",
    "for group in groups:\n",
    "    plt.subplot(len(groups), 1, i)\n",
    "    plt.plot(daily_average_airquality_data_concentrations.index,values[:, group])\n",
    "    plt.title(daily_average_airquality_data_concentrations.columns[group], loc='right', y=0.5)\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel(daily_average_airquality_data_concentrations.columns[group])\n",
    "    i += 1\n",
    "    \n",
    "plt.savefig(os.path.join(filepath ,\"daily_average_airquality_data_concentrations_linegraph.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the airquality timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airquality_pm25_values = values[:, 1]\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(daily_average_airquality_data_concentrations.index, airquality_pm25_values)\n",
    "plt.title('PM2.5 Daily Concentrations')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('PM2.5 Concentration(ug/m3)')\n",
    "plt.savefig(os.path.join(filepath ,\"daily_average_pm25_concentration_trend_linegraph.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the date of the first and last record of the daily airquality dataset\n",
    "This is essential to understand the date range for records from meteorology that shall be merged to this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the lower boundary date from the daily airquality dataset\n",
    "daily_average_airquality_data_concentrations.iloc[:1,:]\n",
    "t= daily_average_airquality_data_concentrations.iloc[:1,:].index.values[0]\n",
    "t = t.astype(datetime.datetime)\n",
    "z= pd.to_datetime(t)\n",
    "daily_average_airquality_data_lower_boundary_date = z.strftime('%Y-%m-%d')\n",
    "\n",
    "print(daily_average_airquality_data_lower_boundary_date)\n",
    "## get the upper boundary date from the daily airquality dataset\n",
    "t = daily_average_airquality_data_concentrations.iloc[-1:,:].index.values[0]\n",
    "t = t.astype(datetime.datetime)\n",
    "z= pd.to_datetime(t)\n",
    "daily_average_airquality_data_upper_boundary_date = z.strftime('%Y-%m-%d')\n",
    "print(daily_average_airquality_data_upper_boundary_date)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the datetime of the first and last record of the hourly airquality dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the lower boundary date from the hourly airquality dataset\n",
    "hourly_average_airquality_data_concentrations.iloc[:1,:]\n",
    "h= hourly_average_airquality_data_concentrations.iloc[:1,:].index.values[0]\n",
    "h = h.astype(datetime.datetime)\n",
    "y= pd.to_datetime(h)\n",
    "hourly_average_airquality_data_lower_boundary_date = y.strftime('%Y-%m-%d %H:%M:%S')\n",
    "  \n",
    "print(hourly_average_airquality_data_lower_boundary_date)\n",
    "## get the upper boundary date from the hourly airquality dataset\n",
    "h = hourly_average_airquality_data_concentrations.iloc[-1:,:].index.values[0]\n",
    "h = h.astype(datetime.datetime)\n",
    "y= pd.to_datetime(h)\n",
    "hourly_average_airquality_data_upper_boundary_date = y.strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(hourly_average_airquality_data_upper_boundary_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing the relationship among the airpollutant concentrations in relation to pm2.5\n",
    "- use scatter plots to determine the extent of correlation and sense of correlation between pm2.5 and other air pollutant concentrations i.e pm1, pm10, co, so2.\n",
    "\n",
    "- this can be acomplished used sns pairplot or matplot pair plot for each pair of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns;\n",
    "sns.pairplot(daily_average_airquality_data_concentrations)\n",
    "plt.savefig(os.path.join(filepath ,\"daily_average_airquality_data_concentrations_pairplot_corr.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_average_airquality_data_concentrations.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the Meteorological data for preprocessing it\n",
    "- read in dataset\n",
    "- display first 10 records\n",
    "- display last 10 records\n",
    "- display dataset summary i.e shape, column names, info and datatypes for each column\n",
    "- generate and display descriptive statistics that summarize the central tendency, dispersion and shape of a dataset’s  distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_meteorological_data = pd.read_csv('data/Met/tahmo_Makerere_Synopticdata_daily.csv')\n",
    "monthly_meteorological_data = pd.read_csv('data/Met/tahmo_Makerere_Synopticdata_monthly.csv')\n",
    "hourly_meteorological_data = pd.read_csv('data/Met/tahmo_Makerere_Synopticdata_hourly.csv')\n",
    "daily_tahmo_unma_rainfall_comparison_data = pd.read_csv('data/Met/tahmo_unma_rainfall_comparison_daily.csv')\n",
    "daily_meteorological_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### comparison of UNMA and tahmo daily rainfall dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_dataframe_info(daily_tahmo_unma_rainfall_comparison_data)\n",
    "daily_tahmo_unma_rainfall_comparison_data_without_missing_records =  daily_tahmo_unma_rainfall_comparison_data.dropna()\n",
    "daily_tahmo_unma_rainfall_comparison_data_without_missing_records[\"Date\"] = pd.to_datetime(daily_tahmo_unma_rainfall_comparison_data_without_missing_records[\"Date\"])\n",
    "daily_tahmo_unma_rainfall_comparison_data_without_missing_values = daily_tahmo_unma_rainfall_comparison_data_without_missing_records.set_index('Date')\n",
    "print(daily_tahmo_unma_rainfall_comparison_data.head(3))\n",
    "show_dataframe_info(daily_tahmo_unma_rainfall_comparison_data_without_missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_tahmo_unma_rainfall_comparison_data_without_missing_values.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#daily_tahmo_unma_rainfall_comparison_data.replace('TR',np.nan, inplace=True)\n",
    "met_cols_to_convert_to_float = ['UNMA',]\n",
    "for col in met_cols_to_convert_to_float:\n",
    "    daily_tahmo_unma_rainfall_comparison_data[col] = pd.to_numeric(daily_tahmo_unma_rainfall_comparison_data[col], errors='coerce')\n",
    "#cleaned_daily_tahmo_unma_rainfall_comparison_data = daily_tahmo_unma_rainfall_comparison_data.replace('TR',np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_dataframe_info(daily_tahmo_unma_rainfall_comparison_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between rainfall observations from unma and tahmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_tahmo_unma_rainfall_comparison_data_correlations= daily_tahmo_unma_rainfall_comparison_data_without_missing_values.corr()\n",
    "daily_tahmo_unma_rainfall_comparison_data_correlations.to_csv(os.path.join(filepath, 'daily_tahmo_unma_rainfall_comparison_data_correlations.csv'))\n",
    "daily_tahmo_unma_rainfall_comparison_data_correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line graphs showing comparison of rainfall dataset from unma and tahmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    fig = plt.figure(figsize=(16,6))\n",
    "    plt.rcParams.update({'font.size':12, 'font.weight':'bold'})\n",
    "    plt.plot(daily_tahmo_unma_rainfall_comparison_data_without_missing_values.index, \n",
    "             daily_tahmo_unma_rainfall_comparison_data_without_missing_values['UNMA'], \n",
    "             color='olive',  linestyle='solid', label='UNMA RAINFALL OBSERVATIONS')\n",
    "    plt.plot(daily_tahmo_unma_rainfall_comparison_data_without_missing_values.index, \n",
    "             daily_tahmo_unma_rainfall_comparison_data_without_missing_values['Tahmo'], \n",
    "             color='chocolate', linestyle='solid', label='Tahmo RAINFALL OBSERVATIONS')\n",
    "   \n",
    "    #marker='o', marker='x',\n",
    "    chart_title =  'Comparison of Daily Rainfall Observations between UNMA and Tahmo '\n",
    "    plt.title(chart_title,fontsize=20)\n",
    "    plt.ylabel('RAINFALL OBSERVATIONS', fontsize=20)\n",
    "    plt.xlabel('Date', fontsize=20)\n",
    "    #plt.margins(0.1)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    path_to_save_file = os.path.join('data','Met')\n",
    "    fig.savefig(os.path.join( path_to_save_file , 'daily_tahmo_unma_rainfall_comparison_data.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_meteorological_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_dataframe_info(daily_meteorological_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_meteorological_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop columns from daily,hourly and monthly meteorological dataset (tahmo) that shall not be used during analysis\n",
    "\n",
    "### daily\n",
    "- site \n",
    "- name\n",
    "- max temperature\n",
    "- min temperature\n",
    "\n",
    "### hourly\n",
    "- site \n",
    "- name\n",
    "\n",
    "### monthly\n",
    "- site \n",
    "- name\n",
    "- min windspeed(m/s)\n",
    "- max windspeed(m/s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_meteorological_data_of_interest = daily_meteorological_data.drop(\n",
    "    ['site','name','min temperature (oC)','max temperature (oC)'], axis=1)\n",
    "\n",
    "hourly_meteorological_data_of_interest = hourly_meteorological_data.drop(['site','name'], axis=1)\n",
    "\n",
    "monthly_meteorological_data_of_interest = monthly_meteorological_data.drop(\n",
    "    ['site','name','min temperature (oC)','max temperature (oC)','max windspeed (m/s)','min windspeed (m/s)'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_meteorological_data_of_interest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_dataframe_info(daily_meteorological_data_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_meteorological_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_dataframe_info(hourly_meteorological_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_meteorological_data_of_interest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_dataframe_info(monthly_meteorological_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Set the day column to be the index for the daily meteorological dataset\n",
    "- parse the  day column into datetime.\n",
    "- set the  day column to be the index for the dataframe.\n",
    "\n",
    "### set the dateTimeUTC to be the index of the hourly meteorological dataset\n",
    "- parse the  dateTimeUTC column into datetime.\n",
    "- set the  dateTimeUTC column to be the index for the dataframe.\n",
    "- change the hourly data from UTC to EAT(Nairobi) ugandanda time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_meteorological_data_of_interest[\"day\"] = pd.to_datetime(daily_meteorological_data_of_interest[\"day\"])\n",
    "daily_meteorological_data_values  = daily_meteorological_data_of_interest.set_index('day')\n",
    "\n",
    "\n",
    "monthly_meteorological_data_of_interest[\"month\"] = pd.to_datetime(monthly_meteorological_data_of_interest[\"month\"])\n",
    "monthly_meteorological_data_values = monthly_meteorological_data_of_interest.set_index('month')\n",
    "\n",
    "hourly_meteorological_data_of_interest[\"dateTimeUTC\"] = pd.to_datetime(hourly_meteorological_data_of_interest[\"dateTimeUTC\"])\n",
    "hourly_meteorological_data_of_interest[\"dateTime\"] = hourly_meteorological_data_of_interest[\"dateTimeUTC\"] + datetime.timedelta(hours=3)\n",
    "hourly_meteorological_data_values = hourly_meteorological_data_of_interest.set_index('dateTime')\n",
    "hourly_meteorological_data_values = hourly_meteorological_data_values.drop(['dateTimeUTC'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis on Monthly Meteorological data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_meteorological_data_values.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_dataframe_info(monthly_meteorological_data_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show histogram distributions for the monthly meteorological data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_meteorological_data_values.hist()\n",
    "plt.savefig(os.path.join(filepath ,\"monthly_meteorological_data_historgram.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analysis on daily meteorological dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_dataframe_info(daily_meteorological_data_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show histogram distributions for the daily meteorology data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_meteorological_data_values.hist()\n",
    "plt.savefig(os.path.join(filepath ,\"daily_meteorological_data_historgram.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_meteorological_data_values.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show histogram distributions for the hourly meteorological data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_meteorological_data_values.hist()\n",
    "plt.savefig(os.path.join(filepath ,\"hourly_meteorological_data_historgram.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding Categorical features (WindDirection)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "mask = daily_meteorological_data_values.dtypes == np.object\n",
    "categorical_cols = daily_meteorological_data_values.columns[mask]\n",
    "\n",
    "# Determine how many extra columns would be created\n",
    "num_ohc_cols = (daily_meteorological_data_values[categorical_cols]\n",
    "                .apply(lambda x: x.nunique())\n",
    "                .sort_values(ascending=False))\n",
    "\n",
    "# No need to encode if there is only one value\n",
    "small_num_ohc_cols = num_ohc_cols.loc[num_ohc_cols>1]\n",
    "\n",
    "# Number of one-hot columns is one less than the number of categories\n",
    "small_num_ohc_cols -= 1\n",
    "print(small_num_ohc_cols.sum())\n",
    "\n",
    "data_ohc = daily_meteorological_data_values.copy()\n",
    "\n",
    "# The encoders\n",
    "le = LabelEncoder()\n",
    "ohc = OneHotEncoder(categories='auto')\n",
    "\n",
    "for col in num_ohc_cols.index:\n",
    "    \n",
    "    # Integer encode the string categories\n",
    "    dat = le.fit_transform(data_ohc[col]).astype(np.int)\n",
    "    \n",
    "    # Remove the original column from the dataframe\n",
    "    data_ohc = data_ohc.drop(col, axis=1)\n",
    "\n",
    "    # One hot encode the data--this returns a sparse array\n",
    "    new_dat = ohc.fit_transform(dat.reshape(-1,1))\n",
    "\n",
    "    # Create unique column names\n",
    "    n_cols = new_dat.shape[1]\n",
    "    col_names = ['_'.join([col, str(x)]) for x in range(n_cols)]\n",
    "\n",
    "    # Create the new dataframe\n",
    "    new_df = pd.DataFrame(new_dat.toarray(), \n",
    "                          index=data_ohc.index, \n",
    "                          columns=col_names)\n",
    "\n",
    "    # Append the new data to the dataframe\n",
    "    data_ohc = pd.concat([data_ohc, new_df], axis=1)\n",
    "    \n",
    "show_dataframe_info(data_ohc)   \n",
    "data_ohc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_meteorological_data_values_onehot =  daily_meteorological_data_values.copy()\n",
    "daily_meteorological_data_values_onehot = pd.get_dummies( daily_meteorological_data_values_onehot, columns=['predominant winddirection'], prefix = ['winddirection'])\n",
    "\n",
    "daily_meteorological_data_values_onehot.head()\n",
    "show_dataframe_info(daily_meteorological_data_values_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_meteorological_data_values_onehot =  hourly_meteorological_data_values.copy()\n",
    "hourly_meteorological_data_values_onehot = pd.get_dummies( hourly_meteorological_data_values_onehot, columns=['winddirection'], prefix = ['winddirection'])\n",
    "\n",
    "hourly_meteorological_data_values_onehot.head()\n",
    "show_dataframe_info(hourly_meteorological_data_values_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining Meteorology data in the same date range as airquality data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_meteorological_data_in_same_daterange_with_daily_airquality_data= daily_meteorological_data_values_onehot[daily_average_airquality_data_lower_boundary_date : daily_average_airquality_data_upper_boundary_date]\n",
    "hourly_meteorological_data_in_same_daterange_with_daily_airquality_data= hourly_meteorological_data_values_onehot[hourly_average_airquality_data_lower_boundary_date : hourly_average_airquality_data_upper_boundary_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_meteorological_data_in_same_daterange_with_daily_airquality_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_dataframe_info(daily_meteorological_data_in_same_daterange_with_daily_airquality_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handle missing data in daily meteorology data by filling NaN with the Mean of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_meteorological_data_with_out_missing_values =daily_meteorological_data_in_same_daterange_with_daily_airquality_data\n",
    "#daily_meteorological_data_with_out_missing_values.fillna(daily_meteorological_data_with_out_missing_values.mean(),inplace=True)\n",
    "show_dataframe_info(daily_meteorological_data_with_out_missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the daily meteorology data values for the time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorological_values = daily_meteorological_data_with_out_missing_values.values\n",
    "# specify columns to plot\n",
    "groups = [0,1,2, 3, 4]\n",
    "i = 1\n",
    "# plot each column\n",
    "\n",
    "plt.figure()\n",
    "for group in groups:\n",
    "    #plt.subplot(len(groups), 1, i)\n",
    "    plt.plot(daily_meteorological_data_with_out_missing_values.index,meteorological_values[:, group])\n",
    "    plt.title(daily_meteorological_data_with_out_missing_values.columns[group], loc='right', y=0.8)\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel(daily_meteorological_data_with_out_missing_values.columns[group])\n",
    "    #i += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "temperature_values = meteorology_values[:, 1]\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(range(len(temperature_values)), temperature_values)\n",
    "plt.title('Temperature Daily Values')\n",
    "plt.xlabel('Sample Records')\n",
    "plt.ylabel('Temperature Values (Degrees F)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vegetation Index (greenness Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_dataframe_info(vi_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi_data_of_interest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi_mask = vi_data.dtypes == np.float64\n",
    "vi_columns = vi_data.columns[vi_mask]\n",
    "#vi_data_of_interest = vi_data[]\n",
    "vi_data_of_interest = vi_data[vi_columns]\n",
    "vi_data_of_interest['TimeStamp'] = vi_data['Date']\n",
    "vi_data_of_interest = vi_data_of_interest.drop(\n",
    "    ['Latitude','Longitude','MOD13A3_006_Sample_X_1km','MOD13A3_006_Line_Y_1km','MOD13A3_006__1_km_monthly_VI_Quality'], axis=1)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi_data_of_interest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " vi_data_of_interest.rename(columns={'MOD13A3_006__1_km_monthly_EVI':'EVI','MOD13A3_006__1_km_monthly_NDVI':'NDVI'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_vi_data = vi_data_of_interest.set_index('TimeStamp')\n",
    "monthly_vi_data_copy = monthly_vi_data.copy()\n",
    "monthly_vi_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysing Relationship between PM2.5 and Greenness ( merging vi dataset and airquality dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_average_airquality_data_concentrations.head()\n",
    "dates = monthly_average_airquality_data_concentrations.index\n",
    "monthly_average_airquality_data_concentrations['MonthOfYear'] = pd.to_datetime(dates).strftime('%m-%Y') \n",
    "monthly_average_airquality_data_concentrations.head()\n",
    "\n",
    "vi_dates = monthly_vi_data.index\n",
    "monthly_vi_data['MonthOfYear'] = pd.to_datetime(vi_dates).strftime('%m-%Y') \n",
    "\n",
    "#print(monthly_average_airquality_data_concentrations.head())\n",
    "#print(monthly_vi_data.head())\n",
    "\n",
    "meteorological_monthly_dates = monthly_meteorological_data_values.index\n",
    "monthly_meteorological_data_values['MonthOfYear'] = pd.to_datetime(meteorological_monthly_dates).strftime('%m-%Y') \n",
    "monthly_meteorological_data_values.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the lower boundary date from the monthly airquality dataset\n",
    "monthly_average_airquality_data_concentrations.iloc[:1,:]\n",
    "first_record= monthly_average_airquality_data_concentrations.iloc[:1,:].index.values[0]\n",
    "first_record = first_record.astype(datetime.datetime)\n",
    "x= pd.to_datetime(first_record)\n",
    "monthly_average_airquality_data_lower_boundary_date = x.strftime('%m-%Y')\n",
    " \n",
    "print(monthly_average_airquality_data_lower_boundary_date)\n",
    "## get the upper boundary date from the monthly airquality dataset\n",
    "last_record = monthly_average_airquality_data_concentrations.iloc[-1:,:].index.values[0]\n",
    "last_record = last_record.astype(datetime.datetime)\n",
    "y = pd.to_datetime(last_record)\n",
    "monthly_average_airquality_data_upper_boundary_date = y.strftime('%m-%Y')\n",
    "print(monthly_average_airquality_data_upper_boundary_date)\n",
    "\n",
    "\n",
    "monthly_combined_airquality_vi_dataset= pd.merge(monthly_average_airquality_data_concentrations, monthly_vi_data, on='MonthOfYear')\n",
    "merged_monthly_airquality_greenness_meteorological_dataset = pd.merge(monthly_combined_airquality_vi_dataset, monthly_meteorological_data_values, on='MonthOfYear')\n",
    "merged_monthly_airquality_vi_dataset = monthly_combined_airquality_vi_dataset.set_index('MonthOfYear')\n",
    "merged_monthly_airquality_greenness_meteorological_dataset = merged_monthly_airquality_greenness_meteorological_dataset.set_index('MonthOfYear')\n",
    "\n",
    "print(merged_monthly_airquality_vi_dataset.head())\n",
    "merged_monthly_airquality_greenness_meteorological_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi_airquality_correlations= merged_monthly_airquality_vi_dataset.corr()\n",
    "vi_airquality_correlations.to_csv(os.path.join(filepath, 'vi_airquality_correlations.csv'))\n",
    "vi_airquality_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_monthly_airquality_vi_dataset_historgram = merged_monthly_airquality_vi_dataset.hist()\n",
    "plt.savefig(os.path.join(filepath ,\"merged_monthly_airquality_vi_dataset_historgram.png\"))\n",
    "plt.show()\n",
    "#merged_monthly_airquality_vi_dataset_historgram_figure = merged_monthly_airquality_vi_dataset_historgram[0].get_figure() \n",
    "#merged_monthly_airquality_vi_dataset_historgram_figure.savefig(os.path.join(filepath ,\"merged_monthly_airquality_vi_dataset_historgram.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_monthly_airquality_vi_sns_plot= sns.pairplot(merged_monthly_airquality_vi_dataset)\n",
    "plt.show()\n",
    "merged_monthly_airquality_vi_sns_plot.savefig(os.path.join(filepath ,\"merged_monthly_airquality_vi_sns_plot.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_monthly_pm25_ndvi = merged_monthly_airquality_vi_dataset[['PM2.5(Ug/m3)', 'NDVI']].copy()\n",
    "merged_monthly_pm25_ndvi.head()\n",
    "corr_plot = sns.regplot(merged_monthly_pm25_ndvi['PM2.5(Ug/m3)'], merged_monthly_pm25_ndvi['NDVI'])\n",
    "corr_plot_figure = corr_plot.get_figure()    \n",
    "corr_plot_figure.savefig(os.path.join(filepath ,\"corr_pm25_vi_reg_plot.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_monthly_pm25_ndvi.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25_ndvi_sns_plot= sns.pairplot(merged_monthly_pm25_ndvi)\n",
    "plt.show()\n",
    "pm25_ndvi_sns_plot.savefig(os.path.join(filepath ,\"monthly_pm25_vi_sns_plot.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_corr_matrix = plt.figure(figsize=(12,6))\n",
    "ax_fig_corr_matrix = fig_corr_matrix.add_subplot(111)\n",
    "cax = ax_fig_corr_matrix.matshow(merged_monthly_pm25_ndvi.corr())\n",
    "plt.xticks(range(len(merged_monthly_pm25_ndvi.columns)), merged_monthly_pm25_ndvi.columns)\n",
    "plt.yticks(range(len(merged_monthly_pm25_ndvi.columns)),merged_monthly_pm25_ndvi.columns)\n",
    "fig_corr_matrix.colorbar(cax)\n",
    "plt.show()\n",
    "\n",
    "fig_corr_matrix.savefig(os.path.join(filepath, 'monthly_pm25_vi_corr_matrix.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining the daily airquality dataset , daily meteorological dataset and greenness(VI) dataset\n",
    " - The vegetation indices are sampled on monthly basis, we upsampled them to get values for daily vi data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_airquality_data =  daily_average_airquality_data_concentrations\n",
    "print(daily_airquality_data.shape)\n",
    "daily_timestamp = daily_airquality_data.index.values\n",
    "print(len(daily_timestamp))\n",
    "daily_airquality_data[\"TimeStamp\"] = daily_timestamp\n",
    "print(daily_airquality_data.columns)\n",
    "daily_airquality_data[\"TimeStamp\"] = pd.to_datetime(daily_airquality_data[\"TimeStamp\"])\n",
    "print(daily_airquality_data.shape)\n",
    "\n",
    "# month and year for merging with vi data\n",
    "daily_airquality_data['MonthOfYear'] = pd.to_datetime(daily_timestamp).strftime('%m-%Y') \n",
    "daily_airquality_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_airquality_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_meteorology_data =  daily_meteorological_data_with_out_missing_values\n",
    "print(daily_meteorology_data.shape)\n",
    "timestamp = daily_meteorology_data.index.values\n",
    "print(len(timestamp))\n",
    "daily_meteorology_data[\"TimeStamp\"] = timestamp\n",
    "print(daily_meteorology_data.columns)\n",
    "daily_meteorology_data[\"TimeStamp\"] = pd.to_datetime(daily_meteorology_data[\"TimeStamp\"])\n",
    "print(daily_meteorology_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_meteorology_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_meteorology_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merging vi  data to daily airquality data\n",
    "   - to comeup with daily airquality data containing vi data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_combined_airquality_vi_dataset= pd.merge(daily_airquality_data, monthly_vi_data, on='MonthOfYear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_combined_airquality_vi_dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_combined_airquality_vi_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_merged_airquality_vi_dataset_of_interest= daily_combined_airquality_vi_dataset.drop(['MonthOfYear'], axis=1)\n",
    "daily_merged_airquality_vi_dataset = daily_merged_airquality_vi_dataset_of_interest.set_index('TimeStamp')\n",
    "daily_merged_airquality_vi_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_merged_airquality_vi_dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_dataframe_info(daily_merged_airquality_vi_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(daily_meteorology_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_combined_dataset= pd.merge( daily_merged_airquality_vi_dataset,daily_meteorology_data, on='TimeStamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_combined_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_dataframe_info(daily_combined_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_combined_dataset.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the time column from combined dataset\n",
    "- make timestamp  the index values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_daily_airquality_greenness_meteorological_dataset  = daily_combined_dataset.set_index('TimeStamp')\n",
    "merged_daily_airquality_greenness_meteorological_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  merging vi  data to hourly airquality and hourly meteorological data\n",
    "   - to comeup with hourly airquality data containing vi data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_meteorological_data_in_same_daterange_with_daily_airquality_data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_dataframe_info(hourly_meteorological_data_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_average_airquality_data_concentrations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_dataframe_info(hourly_average_airquality_data_concentrations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_airquality_data =  hourly_average_airquality_data_concentrations\n",
    "print(hourly_airquality_data.shape)\n",
    "hourly_timestamp = hourly_airquality_data.index.values\n",
    "print(len(hourly_timestamp))\n",
    "hourly_airquality_data[\"TimeStamp\"] = hourly_timestamp\n",
    "print(hourly_airquality_data.columns)\n",
    "hourly_airquality_data[\"TimeStamp\"] = pd.to_datetime(hourly_airquality_data[\"TimeStamp\"])\n",
    "print(hourly_airquality_data.shape)\n",
    "\n",
    "# month and year for merging with vi data\n",
    "hourly_airquality_data['MonthOfYear'] = pd.to_datetime(hourly_timestamp).strftime('%m-%Y') \n",
    "hourly_airquality_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_meteorology_data =  hourly_meteorological_data_in_same_daterange_with_daily_airquality_data\n",
    "print(hourly_meteorology_data.shape)\n",
    "hourly_timestamp = hourly_meteorology_data.index.values\n",
    "#print(len(hourly_timestamp))\n",
    "hourly_meteorology_data[\"TimeStamp\"] = hourly_timestamp\n",
    "#print(hourly_meteorology_data.columns)\n",
    "hourly_meteorology_data[\"TimeStamp\"] = pd.to_datetime(hourly_meteorology_data[\"TimeStamp\"])\n",
    "print(hourly_meteorology_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_combined_airquality_vi_dataset= pd.merge(hourly_airquality_data, monthly_vi_data, on='MonthOfYear')\n",
    "hourly_merged_airquality_vi_dataset_of_interest = hourly_combined_airquality_vi_dataset.drop(['MonthOfYear'], axis=1)\n",
    "hourly_merged_airquality_vi_dataset = hourly_merged_airquality_vi_dataset_of_interest.set_index('TimeStamp')\n",
    "hourly_merged_airquality_vi_dataset.head()\n",
    "#hourly_combined_airquality_vi_dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_combined_dataset= pd.merge(hourly_merged_airquality_vi_dataset,hourly_meteorology_data, on='TimeStamp')\n",
    "merged_hourly_airquality_greenness_meteorological_dataset  = hourly_combined_dataset.set_index('TimeStamp')\n",
    "merged_hourly_airquality_greenness_meteorological_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_dataframe_info(hourly_combined_dataset)\n",
    "merged_hourly_airquality_greenness_meteorological_dataset = merged_hourly_airquality_greenness_meteorological_dataset.drop(['Hour'], axis=1)\n",
    "merged_hourly_airquality_greenness_meteorological_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the combined datasets to the respective folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_monthly_airquality_greenness_meteorological_dataset.to_csv(os.path.join(filepath , 'merged_monthly_airquality_greenness_meteorological_dataset.csv'))\n",
    "merged_daily_airquality_greenness_meteorological_dataset.to_csv(os.path.join(filepath , 'merged_daily_airquality_greenness_meteorological_dataset.csv'))\n",
    "merged_hourly_airquality_greenness_meteorological_dataset.to_csv(os.path.join(filepath , 'merged_hourly_airquality_greenness_meteorological_dataset.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "air_quality_prediction_data_preprocesing.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
