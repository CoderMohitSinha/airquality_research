{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L3-ikINq_CDz"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import os\n",
    "import datetime\n",
    "import math"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "YgmwH-BI_txh",
    "outputId": "dd59d1ca-f56f-405b-ae1b-f867bef2c512"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "InRp4djsBMwh"
   },
   "outputs": [],
   "source": [
    "#!ls \"/content/drive/My Drive/Uni/Msc Comp Science/Year Two/Research/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "geukmPjkSbyn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_dataframe_info(df):\n",
    "    print(df.shape)\n",
    "    print(list(df.columns.values))\n",
    "    print('\\n dataframe info: \\n', df.info())\n",
    "    print('\\n dataframe column datatypes:\\n', df.dtypes)\n",
    "    \n",
    "def calculate_rmse(actual_values,predictions):\n",
    "    mse= mean_squared_error(actual_values, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "plt.gcf().subplots_adjust(bottom=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478
    },
    "colab_type": "code",
    "id": "SYFacJONAbXp",
    "outputId": "09eebaf5-610a-4c66-c4a1-cfa929ec9b46"
   },
   "outputs": [],
   "source": [
    "#airquality_data = pd.read_csv('/content/drive/My Drive/Uni/Msc Comp Science/Year Two/Research/experiments/data/AirQuality/AirQo/Bugolobi(ambrosoli)/bugolobi.csv')\n",
    "\n",
    "root_data_dir = 'data'\n",
    "base_dir ='data\\AirQuality\\AirQo'\n",
    "\n",
    "#airquality_data = pd.read_csv(os.path.join(base_dir,'Makerere','merged_hourly_airquality_greenness_meteorological_dataset.csv'))\n",
    "#filepath= os.path.join(base_dir,'Makerere','all_features')\n",
    "#filepath= os.path.join(base_dir,'Makerere','three_features')\n",
    "#filepath= os.path.join(base_dir,'Makerere','three_features','100-lstm-units')\n",
    "#sensor_type = 0\n",
    "\n",
    "#airquality_data = pd.read_csv(os.path.join(base_dir,'Bugolobi(ambrosoli)','merged_hourly_airquality_greenness_meteorological_dataset.csv'))\n",
    "#filepath= os.path.join(base_dir,'Bugolobi(ambrosoli)','three_features')\n",
    "#filepath= os.path.join(base_dir,'Bugolobi(ambrosoli)','three_features','100-lstm-units')\n",
    "#sensor_type = 0\n",
    "\n",
    "#airquality_data = pd.read_csv(os.path.join(base_dir,'Mulago','merged_hourly_airquality_greenness_meteorological_dataset.csv'))\n",
    "#filepath= os.path.join(base_dir,'Mulago','all_features')\n",
    "#filepath= os.path.join(base_dir,'Mulago','three_features')\n",
    "#filepath= os.path.join(base_dir,'Mulago','three_features','100-lstm-units')\n",
    "#sensor_type = 0\n",
    "\n",
    "airquality_data = pd.read_csv(os.path.join(base_dir,'Makindye','merged_hourly_airquality_greenness_meteorological_dataset.csv'))\n",
    "#filepath = os.path.join(base_dir, 'Makindye','SelectedFeatures')\n",
    "#filepath= os.path.join(base_dir,'Makindye','all_features')\n",
    "#filepath= os.path.join(base_dir,'Makindye','three_features')\n",
    "filepath= os.path.join(base_dir,'Makindye','three_features','100-lstm-units')\n",
    "sensor_type = 0\n",
    "\n",
    "#airquality_data = pd.read_csv(os.path.join(base_dir,'Bukoto(kisu)','merged_hourly_airquality_greenness_meteorological_dataset.csv'))\n",
    "#filepath= os.path.join(base_dir,'Bukoto(kisu)', 'SelectedFeatures')\n",
    "#filepath= os.path.join(base_dir,'Bukoto(kisu)','all_features')\n",
    "#filepath= os.path.join(base_dir,'Bukoto(kisu)','three_features')\n",
    "#filepath= os.path.join(base_dir,'Bukoto(kisu)','three_features','100-lstm-units')\n",
    "#sensor_type = 0\n",
    "\n",
    "#airquality_data = pd.read_csv(os.path.join(base_dir,'Lubowa','merged_hourly_airquality_greenness_meteorological_dataset.csv'))\n",
    "#filepath= os.path.join(base_dir,'Lubowa','all_features')\n",
    "#filepath= os.path.join(base_dir,'Lubowa','three_features')\n",
    "#filepath= os.path.join(base_dir,'Lubowa','three_features','100-lstm-units')\n",
    "#sensor_type = 0\n",
    "\n",
    "#airquality_data = pd.read_csv(os.path.join(base_dir,'Jinja_Road(NEMAHOUSE)','merged_hourly_airquality_greenness_meteorological_dataset.csv '))\n",
    "#filepath= os.path.join(base_dir,'Jinja_Road(NEMAHOUSE)','all_features')\n",
    "#filepath= os.path.join(base_dir,'Jinja_Road(NEMAHOUSE)','three_features')\n",
    "#filepath= os.path.join(base_dir,'Jinja_Road(NEMAHOUSE)','three_features','100-lstm-units')\n",
    "#sensor_type = 1\n",
    "\n",
    "#airquality_data = pd.read_csv(os.path.join(base_dir,'Rubaga_Kabusu','merged_hourly_airquality_greenness_meteorological_dataset.csv'))\n",
    "#filepath= os.path.join(base_dir,'Rubaga_Kabusu','all_features')\n",
    "#filepath= os.path.join(base_dir,'Rubaga_Kabusu','three_features')\n",
    "#filepath= os.path.join(base_dir,'Rubaga_Kabusu','three_features','100-lstm-units')\n",
    "#sensor_type = 1\n",
    "\n",
    "#airquality_data = pd.read_csv(os.path.join(base_dir,'Kireka','merged_hourly_airquality_greenness_meteorological_dataset.csv'))\n",
    "#filepath= os.path.join(base_dir,'Kireka','all_features')\n",
    "#filepath= os.path.join(base_dir,'Kireka','three_features')\n",
    "#filepath= os.path.join(base_dir,'Kireka','three_features','100-lstm-units')\n",
    "#sensor_type = 1\n",
    "\n",
    "#airquality_data = pd.read_csv(os.path.join(base_dir, 'Nsambya(American_Embassy)','merged_hourly_airquality_greenness_meteorological_dataset.csv '))\n",
    "#filepath = os.path.join(base_dir, 'Nsambya(American_Embassy)','SelectedFeatures')\n",
    "#filepath= os.path.join(base_dir,'Nsambya(American_Embassy)','all_features')\n",
    "#filepath= os.path.join(base_dir,'Nsambya(American_Embassy)','three_features')\n",
    "#filepath= os.path.join(base_dir,'Nsambya(American_Embassy)','three_features','100-lstm-units')\n",
    "#sensor_type = 2\n",
    "\n",
    "airquality_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ftQn1R_02W9o"
   },
   "outputs": [],
   "source": [
    "airquality_data_copy = airquality_data.copy()\n",
    "airquality_data[\"TimeStamp\"] = pd.to_datetime(airquality_data[\"TimeStamp\"])\n",
    "airquality_data = airquality_data.set_index('TimeStamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "correlations = pd.DataFrame(airquality_data).corr(method='pearson')\n",
    "correlations.to_csv(os.path.join(filepath, 'training_correlations.csv'))\n",
    "plt.figure(figsize=(24,12))\n",
    "training_features_corr_plot = sns.heatmap(correlations, annot=True, cmap=plt.cm.Reds)\n",
    "correlation_plot_figure = training_features_corr_plot.get_figure()    \n",
    "correlation_plot_figure.savefig(os.path.join(filepath ,\"training_correlations_heatmap_plot.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "dr = DecisionTreeRegressor().fit(training_features, training_targets)\n",
    "dr.feature_importances_\n",
    "pd.Series(dr.feature_importances_, index=training_features.columns[0:]).plot.bar(color='steelblue', figsize=(12, 6))\n",
    "\n",
    "feature_importance_dictionary = {}\n",
    "for feature, importance in zip(training_features.columns, dr.feature_importances_):\n",
    "    feature_importance_dictionary[feature] = importance\n",
    "    \n",
    "feature_importances = pd.DataFrame.from_dict(feature_importance_dictionary, orient='index').rename(columns={0: 'Feature-importance'})\n",
    "feature_importances.sort_values(by='Feature-importance').plot(kind='bar', rot=90, figsize=(12,12))\n",
    "plt.savefig(os.path.join(filepath, 'feature_importance.png'))\n",
    "sorted_feature_importances = feature_importances.sort_values(by='Feature-importance')\n",
    "sorted_feature_importances.to_csv(os.path.join(filepath, 'feature_importance.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rl-Q0Swy2W9t"
   },
   "outputs": [],
   "source": [
    "if sensor_type == 0:\n",
    "    #pm1 and pm10 and pm2.5\n",
    "    airquality_data_for_selected_features = airquality_data.drop(['hour', 'EVI', 'NDVI',\n",
    "       'humidity (%)', 'precipitation (mm)', 'pressure (kPa)',\n",
    "       'radiation (W/m2)', 'windspeed (m/s)',\n",
    "       'winddirection_E', 'winddirection_N', 'winddirection_NE',\n",
    "       'winddirection_NW', 'winddirection_S', 'winddirection_SE',\n",
    "       'winddirection_SW', 'winddirection_W','temperature (oC)'], axis=1)\n",
    "    \n",
    "elif sensor_type == 1:\n",
    "    #'temperature (oC)','PM10(Ug/m3)'\n",
    "    airquality_data_for_selected_features = airquality_data.drop(['hour', 'EVI', 'NDVI',\n",
    "       'humidity (%)', 'precipitation (mm)', 'pressure (kPa)',\n",
    "       'radiation (W/m2)', 'windspeed (m/s)',\n",
    "       'winddirection_E', 'winddirection_N', 'winddirection_NE',\n",
    "       'winddirection_NW', 'winddirection_S', 'winddirection_SE',\n",
    "       'winddirection_SW', 'winddirection_W'], axis=1)\n",
    "    \n",
    "elif sensor_type == 2:\n",
    "    #temperature , hour\n",
    "    airquality_data_for_selected_features = airquality_data.drop([ 'EVI', 'NDVI',\n",
    "       'humidity (%)', 'precipitation (mm)', 'pressure (kPa)',\n",
    "       'radiation (W/m2)', 'windspeed (m/s)',\n",
    "       'winddirection_E', 'winddirection_N', 'winddirection_NE',\n",
    "       'winddirection_NW', 'winddirection_S', 'winddirection_SE',\n",
    "       'winddirection_SW', 'winddirection_W'], axis=1)\n",
    "    \n",
    "#temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nCH7dg6uSby0"
   },
   "outputs": [],
   "source": [
    "airquality_data_for_selected_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ho2ych4lB3cA"
   },
   "outputs": [],
   "source": [
    "airquality_data_for_selected_features.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LueXKLM3B_DR"
   },
   "outputs": [],
   "source": [
    "show_dataframe_info(airquality_data_for_selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6inajEGHCWNw"
   },
   "outputs": [],
   "source": [
    "airquality_data_for_selected_features.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_QqtVZw7Sb3i"
   },
   "source": [
    "### Separate Features From the Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y5tqylHa2W-Y"
   },
   "outputs": [],
   "source": [
    "airquality_data_for_selected_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airquality_data_for_selected_features_copy = airquality_data_for_selected_features.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4sPre3D-2W-6"
   },
   "outputs": [],
   "source": [
    "airquality_data_for_selected_features = airquality_data_for_selected_features.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LvOH8t25Sb4E"
   },
   "source": [
    "\n",
    "### separate test dataset from training dataset and validation dataset\n",
    "- separate data on 70/10/20 training/validation/testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ahZvu1i-2W_A"
   },
   "outputs": [],
   "source": [
    "training_data_length = math.floor(len(airquality_data_for_selected_features)* 0.7)\n",
    "print(training_data_length)\n",
    "\n",
    "validation_data_length = math.floor(len(airquality_data_for_selected_features)*0.1)\n",
    "print(validation_data_length)\n",
    "\n",
    "testing_data_length = math.floor(len(airquality_data_for_selected_features)* 0.2)\n",
    "print(testing_data_length)\n",
    "\n",
    "print(str(training_data_length + validation_data_length + testing_data_length ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yiqwv889Sb4E"
   },
   "outputs": [],
   "source": [
    "training_data = airquality_data_for_selected_features[0:training_data_length,:]\n",
    "print(training_data.shape)\n",
    "\n",
    "validation_data = airquality_data_for_selected_features[training_data_length:training_data_length+validation_data_length,:]\n",
    "print(validation_data.shape)\n",
    "\n",
    "testing_data = airquality_data_for_selected_features[training_data_length+validation_data_length: training_data_length+validation_data_length+testing_data_length,:]\n",
    "print(testing_data.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qchOsoA0Sb3A"
   },
   "source": [
    "### Preprocess the data to a format a neural network can ingest.\n",
    "- Normalising/Scaling data using minmax scaler in sklearn preprocessing for each dataset separately\n",
    "- Generationg sequential data from the recent past (e.g 3hrs), along with a target pm2.5 value in the future (next day)  for the\n",
    "  * training dataset\n",
    "  * validation dataset\n",
    "  * test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GpJLPXVa2W_b"
   },
   "outputs": [],
   "source": [
    "def generate_dataset_in_format_lstm_can_ingest(data, look_back=1):\n",
    "    x_data, y_data = [], []\n",
    "    for i in range(len(data)-look_back-1):\n",
    "        feature_data = data[i:(i+look_back), 0]\n",
    "        x_data.append(feature_data)\n",
    "        y_data.append(data[i + look_back, 0])\n",
    "    return np.array(x_data), np.array(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## format series to supervised problem.. example obtained from machine learning mastery. Number of lag observations, number of observations as output\n",
    "def generate_multivariate_dataset_in_format_lstm_can_ingest(data, number_of_inputs, number_of_outputs, dropnan=True):\n",
    "    number_of_variables = 1 if type(data) is list else data.shape[1]\n",
    "    data_frame= pd.DataFrame(data)\n",
    "    columnsx, names = list(),list()\n",
    "    #generate input sequence (t-n, ... t-1)\n",
    "    for i in range(number_of_inputs, 0, -1):\n",
    "        columnsx.append(data_frame.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(number_of_variables)]\n",
    "       # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, number_of_outputs):\n",
    "        columnsx.append(data_frame.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(number_of_variables)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(number_of_variables)]\n",
    "            \n",
    "    \n",
    "    aggregated_df = pd.concat(columnsx, axis=1)\n",
    "    aggregated_df.columns = names\n",
    "    \n",
    "    if dropnan:\n",
    "        aggregated_df.dropna(inplace=True)\n",
    "    return aggregated_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 1\n",
    "number_of_features = 1\n",
    "number_of_outputs = 1\n",
    "transformed_training_data = generate_multivariate_dataset_in_format_lstm_can_ingest(training_data, timesteps, number_of_outputs)\n",
    "transformed_training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TDXADXdT2W_g"
   },
   "source": [
    "### given data that goes back a number of timesteps e.g 3hrs, can we predict the next hour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LpEnC6fs2W_h"
   },
   "source": [
    "### training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape into X=t and Y=t+1 timesteps = lookback\n",
    "timesteps = 1\n",
    "number_of_features = 1\n",
    "number_of_outputs = 1\n",
    "transformed_training_data = generate_multivariate_dataset_in_format_lstm_can_ingest(training_data, timesteps, number_of_outputs)\n",
    "# drop columns we don't want to predict...21 is pm2.5 we want to predict\n",
    "if sensor_type == 0:\n",
    "    transformed_training_data.drop(transformed_training_data.columns[[3,5]], axis=1, inplace=True)\n",
    "    print(transformed_training_data.columns)\n",
    "elif sensor_type == 1:\n",
    "    transformed_training_data.drop(transformed_training_data.columns[[4,5]], axis=1, inplace=True)\n",
    "    print(transformed_training_data.columns)\n",
    "elif sensor_type == 2:\n",
    "    transformed_training_data.drop(transformed_training_data.columns[[4,5]], axis=1, inplace=True)\n",
    "    print(transformed_training_data.columns)\n",
    "\n",
    "\n",
    "transformed_training_data_values = transformed_training_data.values\n",
    "scaler = MinMaxScaler()\n",
    "training_features =transformed_training_data_values[:, :-1]\n",
    "scaled_training_features_original = scaler.fit_transform(training_features)\n",
    "training_targets = transformed_training_data_values[:, -1]\n",
    "\n",
    "scaled_training_features = np.reshape(scaled_training_features_original, \n",
    "                                      (scaled_training_features_original.shape[0], timesteps, scaled_training_features_original.shape[1]))\n",
    "print(scaled_training_features.shape, training_targets.shape, scaled_training_features_original.shape )\n",
    "transformed_training_data.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_training_data.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2rUqfzEj2XHf"
   },
   "source": [
    "### validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9K3nO_QW2XHg"
   },
   "outputs": [],
   "source": [
    "transformed_validation_data = generate_multivariate_dataset_in_format_lstm_can_ingest(validation_data, timesteps, number_of_outputs)\n",
    "\n",
    "if sensor_type == 0:\n",
    "    transformed_validation_data.drop(transformed_validation_data.columns[[3,5]], axis=1, inplace=True)\n",
    "    print(transformed_validation_data.columns)\n",
    "elif sensor_type == 1:\n",
    "    transformed_validation_data.drop(transformed_validation_data.columns[[4,5]], axis=1, inplace=True)\n",
    "    print(transformed_validation_data.columns)\n",
    "elif sensor_type == 2:\n",
    "    transformed_validation_data.drop(transformed_validation_data.columns[[4,5]], axis=1, inplace=True)\n",
    "    print(transformed_validation_data.columns)\n",
    "\n",
    "##convert dataframe to array form\n",
    "transformed_validation_data_values = transformed_validation_data.values\n",
    "validation_features = transformed_validation_data_values[:, :-1]\n",
    "validation_targets =  transformed_validation_data_values[:, -1]\n",
    "scaled_validation_features_original = scaler.fit_transform(validation_features)\n",
    "# reshape validation features to [samples, time steps, features]\n",
    "scaled_validation_features = np.reshape(scaled_validation_features_original, \n",
    "                                      (scaled_validation_features_original.shape[0], timesteps, scaled_validation_features_original.shape[1]))\n",
    "\n",
    "print(scaled_validation_features.shape, validation_targets.shape, scaled_validation_features_original.shape )\n",
    "transformed_validation_data.head().T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DNtoE6H22XHl"
   },
   "source": [
    "### Testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_testing_data = generate_multivariate_dataset_in_format_lstm_can_ingest(testing_data,\n",
    "                                                                                   timesteps, number_of_outputs)\n",
    "\n",
    "if sensor_type == 0:\n",
    "    transformed_testing_data.drop(transformed_testing_data.columns[[3,5]], axis=1, inplace=True)\n",
    "elif sensor_type == 1:\n",
    "    transformed_testing_data.drop(transformed_testing_data.columns[[4,5]], axis=1, inplace=True)\n",
    "elif sensor_type == 2:\n",
    "    transformed_testing_data.drop(transformed_testing_data.columns[[4,5]], axis=1, inplace=True)\n",
    "\n",
    "print(transformed_testing_data.columns)\n",
    "\n",
    "transformed_testing_data_values = transformed_testing_data.values\n",
    "testing_features =  transformed_testing_data_values[:, :-1]\n",
    "testing_targets =  transformed_testing_data_values[:, -1]\n",
    "\n",
    "test_scaler = MinMaxScaler()\n",
    "scaled_testing_features_original = test_scaler.fit_transform(testing_features)\n",
    "# reshape testing features to [samples, timesteps, features]\n",
    "scaled_testing_features = np.reshape(scaled_testing_features_original, \n",
    "                                      (scaled_testing_features_original.shape[0], timesteps, scaled_testing_features_original.shape[1]))\n",
    "\n",
    "print(scaled_testing_features.shape, testing_targets.shape, scaled_testing_features_original.shape )\n",
    "transformed_testing_data.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2NYYNr3J2XH5"
   },
   "source": [
    "### SUPPORT VECTOR REGRESSION APPROACH\n",
    "- Training and evaluation on support vector regression approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S0qt0M402XH6"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "svr = SVR(kernel='rbf', degree=3, C=100, epsilon=0.1)\n",
    "# fit the model by fitting the SVM regressor to the training data\n",
    "svr.fit(scaled_training_features_original,training_targets.ravel())\n",
    "svr_predictions = svr.predict(scaled_testing_features_original)\n",
    "print(svr_predictions.shape)\n",
    "print(svr_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_predictions = svr_predictions.reshape(-1, 1)\n",
    "svr_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_testing_features_original.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inverting the predictions and actual values from standardized form"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "svr_testing_predictions_unscaled = scaler.inverse_transform(svr_predictions)\n",
    "#print(testing_data_unscaled.shape)\n",
    "#restored_original_scaled_testing_data_shape.shape\n",
    "#testing_targets_unscaled[0:5]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "svr_testing_predictions_unscaled.ravel()\n",
    "testing_targets.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_predictions.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G0ZZNqj72XH-"
   },
   "outputs": [],
   "source": [
    "#svr_testing_predictions_unscaled = scaler.inverse_transform(svr_predictions)\n",
    "svr_mae = mean_absolute_error(testing_targets, svr_predictions)\n",
    "print('SVR MAE: ', svr_mae.round(2))\n",
    "svr_rmse = calculate_rmse(testing_targets, svr_predictions)\n",
    "print('SVR RMSE: ', svr_rmse.round(2))\n",
    "svr_prediction_vs_actual_dataframe = pd.DataFrame({'Actual PM2.5': testing_targets.ravel(), 'Predicted PM2.5':svr_predictions.ravel()}) \n",
    "svr_prediction_vs_actual_dataframe\n",
    "\n",
    "## save predictions by svr\n",
    "svr_prediction_vs_actual_dataframe.to_csv(os.path.join(filepath , 'svr_predictions.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_svr_predictions_vs_actual = plt.figure(figsize=(12,6))\n",
    "ax_fig_svr_predictions_vs_actual = fig_svr_predictions_vs_actual.add_subplot(111)\n",
    "plt.plot(testing_targets, color = 'red', label = 'Actual PM2.5 Values')\n",
    "plt.plot(svr_predictions, color = 'blue', label = 'Predicted PM2.5 Values')\n",
    "plt.title('Predicted PM2.5  Vs Actual PM2.5 ')\n",
    "plt.xlabel('PM2.5 Records')\n",
    "plt.ylabel('PM2.5 Values')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "fig_svr_predictions_vs_actual.savefig(os.path.join(filepath, 'svr_model_prediction_vs_actual.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Process Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import ConstantKernel, RBF\n",
    "\n",
    "#kernel =   RBF(length_scale=1.0)\n",
    "rbf_kernel = ConstantKernel(1.0) * RBF(length_scale=1.0)\n",
    "gp = GaussianProcessRegressor(kernel=rbf_kernel)\n",
    "\n",
    "gp.fit(scaled_training_features_original,training_targets.reshape(-1,1))\n",
    "\n",
    "gp_predictions, sigma = gp.predict(scaled_testing_features_original, return_std=True)\n",
    "\n",
    "print(gp_predictions.shape)\n",
    "\n",
    "gp_regression_score = gp.score(scaled_testing_features_original, testing_targets)\n",
    "print(gp_regression_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gp_testing_predictions_unscaled = scaler.inverse_transform(gp_predictions)\n",
    "gp_mae = mean_absolute_error(testing_targets, gp_predictions)\n",
    "print('GP MAE: ', gp_mae.round(2))\n",
    "gp_rmse = calculate_rmse(testing_targets, gp_predictions)\n",
    "print('GP RMSE: ', gp_rmse.round(2))\n",
    "gp_prediction_vs_actual_dataframe = pd.DataFrame({'Actual PM2.5': testing_targets.ravel(), 'Predicted PM2.5':gp_predictions.ravel()}) \n",
    "gp_prediction_vs_actual_dataframe\n",
    "\n",
    "## save predictions by gp\n",
    "gp_prediction_vs_actual_dataframe.to_csv(os.path.join(filepath , 'gp_predictions.csv'))\n",
    "\n",
    "fig_gp_predictions_vs_actual = plt.figure(figsize=(12,6))\n",
    "ax_fig_gp_predictions_vs_actual = fig_gp_predictions_vs_actual.add_subplot(111)\n",
    "plt.plot(testing_targets, color = 'red', label = 'Actual PM2.5 Values')\n",
    "plt.plot(gp_predictions, color = 'blue', label = 'Predicted PM2.5 Values')\n",
    "plt.title('Predicted PM2.5 Vs Actual PM2.5 ')\n",
    "plt.xlabel('PM2.5 Records')\n",
    "plt.ylabel('PM2.5 Values')\n",
    "plt.legend()\n",
    "fig_gp_predictions_vs_actual.savefig(os.path.join(filepath, 'gp_model_prediction_vs_actual.png'))\n",
    "\n",
    "with open(os.path.join(filepath, \"results_summary_gaussian_process_model.txt\"), \"w+\") as text_file:\n",
    "        print(\"GP RMSE: {} \\n GP MAE: {}\"\n",
    "              .format(gp_rmse.round(2), gp_mae.round(2)), file=text_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NWJELt102XID"
   },
   "source": [
    "### BASIC LSTM MODOEL\n",
    "- Training and evaluating on basic lstm model with one layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_training_features.shape[1], scaled_training_features.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LUzooi-O2XIE"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "#from keras.models import load_model\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return backend.sqrt(backend.mean(backend.square(y_pred - y_true)))\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return backend.sqrt(backend.mean(backend.square(y_pred - y_true)))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape = (scaled_training_features.shape[1], scaled_training_features.shape[2]))) #timesteps, seq_length(no of features)\n",
    "model.add(Dense(1))\n",
    "\n",
    "callbacks_list = [\n",
    "    EarlyStopping(  # interrupts training when improvement stops \n",
    "        monitor='val_loss', \n",
    "        patience=10, \n",
    "        mode='min'), \n",
    "    \n",
    "   ModelCheckpoint( #saves the current weights after every epock\n",
    "        filepath=os.path.join(filepath, 'basic_lstm_model.h5'),\n",
    "        monitor='val_loss',save_best_only=True) # these 2 arguments mean , you won't overwrite the model file unless val_loss has improved which  allows you to keep the best model seen during training.\n",
    "]\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics = ['mean_absolute_error', rmse])\n",
    "basic_model_history = model.fit(scaled_training_features, training_targets, epochs=50,\n",
    "                                validation_data=(scaled_validation_features, validation_targets),\n",
    "                               callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YEwyHV1o2XIK"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PZL3AsR92XIR"
   },
   "outputs": [],
   "source": [
    "basic_model_architecture_path = os.path.join(filepath, 'basic_model_plot.png')\n",
    "plot_model(model, to_file=basic_model_architecture_path, show_shapes=False, show_layer_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uL8eqrcs2XIa",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss = basic_model_history.history['loss']\n",
    "val_loss = basic_model_history.history['val_loss']\n",
    "\n",
    "epochs = range(len(loss))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig(os.path.join(filepath, 'basic_model_history_training_validation_loss.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lsH0QO0v2XId"
   },
   "outputs": [],
   "source": [
    "print(np.argmin(val_loss))\n",
    "#val_loss[70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EDgTEYNe2XIg"
   },
   "outputs": [],
   "source": [
    "hist_rmse = basic_model_history.history['rmse']\n",
    "val_rmse = basic_model_history.history['val_rmse']\n",
    "epochs = range(len(hist_rmse))\n",
    "\n",
    "fig_rmse = plt.figure()\n",
    "ax_rmse= fig_rmse.add_subplot(111)\n",
    "\n",
    "plt.plot(epochs, hist_rmse, 'bo', label='Training Root Mean Square Error')\n",
    "plt.plot(epochs, val_rmse, 'r', label='Validation Root Mean Square Error')\n",
    "plt.title('Training and Validation Root Mean Square Error')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig_rmse.savefig(os.path.join(filepath, 'basic_model_history_training_validation_RMSE.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vSw3rqR92XIk",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mae = basic_model_history.history['mean_absolute_error']\n",
    "val_mae = basic_model_history.history['val_mean_absolute_error']\n",
    "epochs = range(len(mae))\n",
    "\n",
    "fig_mae = plt.figure()\n",
    "ax_mae = fig_mae.add_subplot(111)\n",
    "\n",
    "plt.plot(epochs, mae, 'bo', label='Training Mean Absolute Error')\n",
    "plt.plot(epochs, val_mae, 'r', label='Validation Mean Absolute Error')\n",
    "plt.title('Training and Validation Mean Absolute Error')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "fig_mae.savefig(os.path.join(filepath, 'basic_model_history_training_validation_mae.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_RR1f5UE2XIr"
   },
   "outputs": [],
   "source": [
    "saved_model = load_model(os.path.join(filepath,'basic_lstm_model.h5'),  custom_objects={'rmse': rmse})\n",
    "\n",
    "basic_lstm_model_train_evaluation = saved_model.evaluate(scaled_training_features, training_targets, verbose=0)\n",
    "basic_lstm_model_test_evaluation = saved_model.evaluate(scaled_testing_features, testing_targets, verbose=0)\n",
    "print(basic_lstm_model_train_evaluation)\n",
    "print(basic_lstm_model_test_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_sYd1zZO2XI4"
   },
   "outputs": [],
   "source": [
    "basic_lstm_model_predictions = saved_model.predict(scaled_testing_features)\n",
    "basic_lstm_model_evaluation =  saved_model.evaluate(scaled_testing_features, testing_targets)\n",
    "print(basic_lstm_model_evaluation)\n",
    "print(saved_model.metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### converting targets and predictions to from scaled values"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "basic_lstm_testing_targets_unscaled = scaler.inverse_transform(scaled_testing_targets)\n",
    "basic_lstm_testing_predictions_unscaled = scaler.inverse_transform(basic_lstm_model_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_lstm_rmse = calculate_rmse(testing_targets, basic_lstm_model_predictions)\n",
    "basic_lstm_mae =  mean_absolute_error(testing_targets, basic_lstm_model_predictions)\n",
    "print('BASIC LSTM RMSE: ', basic_lstm_rmse.round(2))\n",
    "print('BASIC LSTM MAE: ', basic_lstm_mae.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_basic_lstm_predictions_vs_actual = plt.figure(figsize=(12,6))\n",
    "ax_fig_basic_lstm_predictions_vs_actual = fig_basic_lstm_predictions_vs_actual.add_subplot(111)\n",
    "plt.plot(testing_targets, color = 'red', label = 'Actual PM2.5 Values')\n",
    "plt.plot(basic_lstm_model_predictions, color = 'blue', label = 'Predicted PM2.5 Values')\n",
    "plt.title('Predicted PM2.5  Vs Actual PM2.5 ')\n",
    "plt.xlabel('PM2.5 Records')\n",
    "plt.ylabel('PM2.5 Values')\n",
    "plt.legend()\n",
    "\n",
    "fig_basic_lstm_predictions_vs_actual.savefig(os.path.join(filepath, 'basic_lstm_model_prediction_vs_actual.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s2K0wBp62XI9"
   },
   "outputs": [],
   "source": [
    "print(basic_lstm_model_predictions.shape)\n",
    "print(basic_lstm_model_predictions.ravel().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZGfCLc2T2XJA"
   },
   "outputs": [],
   "source": [
    "basic_lstm_model_prediction_vs_actual_dataframe = pd.DataFrame({'Actual PM2.5': testing_targets.ravel(), 'Predicted PM2.5':basic_lstm_model_predictions.ravel()}) \n",
    "basic_lstm_model_prediction_vs_actual_dataframe\n",
    "## save predictions by basic lstm model\n",
    "basic_lstm_model_prediction_vs_actual_dataframe.to_csv(os.path.join(filepath , 'basic_lstm_model_predictions.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WBitZDTLSb4P"
   },
   "source": [
    "### Creation of Neural Network Architecture,Training & Evaluation  on Stacked LSTM and DROPOUT layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IenaENnPSb4Q",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "deep_lstm_callbacks_list = [\n",
    "    EarlyStopping(  # interrupts training when improvement stops \n",
    "        monitor='val_loss', \n",
    "        patience=10, \n",
    "        mode='min'), \n",
    "    \n",
    "   ModelCheckpoint( #saves the current weights after every epock\n",
    "        filepath=os.path.join(filepath, 'deep_lstm_best_model.h5'),\n",
    "        monitor='val_loss',save_best_only=True) # these 2 arguments mean , you won't overwrite the model file unless val_loss has improved which  allows you to keep the best model seen during training.\n",
    "]\n",
    "\n",
    "regressor_model = Sequential()\n",
    "#8,4,4\n",
    "regressor_model.add(LSTM(units=100, return_sequences = True, input_shape = (scaled_training_features.shape[1],scaled_training_features.shape[2])))\n",
    "regressor_model.add(Dropout(0.2))\n",
    "regressor_model.add(LSTM(units = 100, return_sequences = True))\n",
    "regressor_model.add(Dropout(0.1))\n",
    "regressor_model.add(LSTM(units = 100))\n",
    "#regressor_model.add(Dropout(0.2))\n",
    "\n",
    "regressor_model.add(Dense(units = 1))\n",
    "\n",
    "regressor_model.compile(optimizer = 'adam', loss = 'mse',metrics = ['mean_absolute_error',rmse] )\n",
    "\n",
    "##Training the model\n",
    "history = regressor_model.fit(scaled_training_features, training_targets,epochs = 100,\n",
    "                              validation_data=(scaled_validation_features, validation_targets), batch_size=32,\n",
    "                              callbacks=deep_lstm_callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fN9EwdUFSb4R"
   },
   "outputs": [],
   "source": [
    "#regressor_model.save('/content/drive/My Drive/Uni/Msc Comp Science/Year Two/Research/experiments/data/AirQuality/AirQo/airquality_prediction_bugolobi_04_20_2019.h5')\n",
    "regressor_model.save(os.path.join(filepath,'airquality_prediction_model.h5'))\n",
    "regressor_model.summary()\n",
    "regressor_model_architecture_path = os.path.join(filepath, 'deep_lstm_model_plot.png')\n",
    "plot_model(regressor_model, to_file=regressor_model_architecture_path, show_shapes=False, show_layer_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PNUn7SCa2XJT"
   },
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(loss))\n",
    "\n",
    "fig_deep_lstm_loss= plt.figure()\n",
    "ax = fig_deep_lstm_loss.add_subplot(111)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig_deep_lstm_loss.savefig(os.path.join(filepath, 'deep_lstm_model_history_training_validation_loss.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MCJ9OT-u2XJn"
   },
   "outputs": [],
   "source": [
    "mae = history.history['mean_absolute_error']\n",
    "val_mae = history.history['val_mean_absolute_error']\n",
    "epochs = range(len(mae))\n",
    "\n",
    "fig_deep_lstm_mae = plt.figure()\n",
    "ax_mae = fig_deep_lstm_mae.add_subplot(111)\n",
    "\n",
    "plt.plot(epochs, mae, 'bo', label='Training Mean Absolute Error')\n",
    "plt.plot(epochs, val_mae, 'r', label='Validation Mean Absolute Error')\n",
    "plt.title('Training and Validation Mean Absolute Error')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig_mae.savefig(os.path.join(filepath, 'deep_lst_mmodel_history_training_validation_mae.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ti0Xaz812XJt"
   },
   "outputs": [],
   "source": [
    "hist_rmse = history.history['rmse']\n",
    "val_rmse = history.history['val_rmse']\n",
    "epochs = range(len(hist_rmse))\n",
    "#figsize=(12,6)\n",
    "fig_rmse = plt.figure()\n",
    "ax_rmse= fig_rmse.add_subplot(111)\n",
    "\n",
    "plt.plot(epochs, hist_rmse, 'bo', label='Training Root Mean Squared Error')\n",
    "plt.plot(epochs, val_rmse, 'r', label='Validation Root Mean Squared Error')\n",
    "plt.title('Training and Validation Root Mean Squared Error')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "fig_rmse.savefig(os.path.join(filepath, 'deep_model_history_training_validation_RMSE.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sO0awXl1Sb4T"
   },
   "source": [
    "### Making predictions (forecasts) using the deep recurrent lstm\n",
    "1. Convert test set in the same format accepted by model\n",
    "1. make the forecasts directly on the testing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RDyMT-YB2XJ0"
   },
   "source": [
    "### Make prediction and evaluation using the developed deep lstm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "99pD-uTa2XJ1"
   },
   "outputs": [],
   "source": [
    "#saved_best_deep_lstm_model = load_model(os.path.join(filepath,'deep_lstm_best_model.h5'),  custom_objects={'rmse': rmse})\n",
    "saved_best_deep_lstm_model = load_model(os.path.join(filepath,'airquality_prediction_model.h5'),  custom_objects={'rmse': rmse})\n",
    "deep_lstm_model_train_evaluation = saved_best_deep_lstm_model.evaluate(scaled_training_features, training_targets, verbose=0)\n",
    "deep_lstm_model_test_evaluation = saved_best_deep_lstm_model.evaluate(scaled_testing_features, testing_targets, verbose=0)\n",
    "print(deep_lstm_model_train_evaluation)\n",
    "print(deep_lstm_model_test_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ts5RRZWoSb4Z"
   },
   "outputs": [],
   "source": [
    "deep_lstm_model_predictions = saved_best_deep_lstm_model.predict(scaled_testing_features)\n",
    "deep_lstm_model_evaluation =  saved_best_deep_lstm_model.evaluate(scaled_testing_features, testing_targets)\n",
    "\n",
    "deep_lstm_rmse = calculate_rmse(testing_targets, deep_lstm_model_predictions )\n",
    "deep_lstm_mae =  mean_absolute_error(testing_targets, deep_lstm_model_predictions)\n",
    "print('Deep LSTM RMSE: ', deep_lstm_rmse.round(2))\n",
    "print('Deep LSTM MAE: ', deep_lstm_mae.round(2))\n",
    "\n",
    "deep_lstm_model_prediction_vs_actual_dataframe = pd.DataFrame({'Actual PM2.5':testing_targets.ravel(), 'Predicted PM2.5':deep_lstm_model_predictions.ravel()}) \n",
    "deep_lstm_model_prediction_vs_actual_dataframe\n",
    "## save predictions by basic lstm model\n",
    "deep_lstm_model_prediction_vs_actual_dataframe.to_csv(os.path.join(filepath , 'deep_lstm_model_predictions.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EQ7BkVaMSb4j"
   },
   "source": [
    "### Verification of the average in the results of the forecasts and in the actual results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pBCyXHz1Sb4h"
   },
   "outputs": [],
   "source": [
    "print('predictions', deep_lstm_model_predictions.mean())\n",
    "print('actual pm2.5 values', testing_targets.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xX5heGwJSb4m"
   },
   "source": [
    "### Visualization of the predictions and actual values of PM2.5\n",
    "1. #### using line graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#added timestep to cater for the shifted records which get droped for having nan values\n",
    "testing_data_for_plotting =airquality_data_copy.loc[training_data_length+validation_data_length+timesteps+1: training_data_length+validation_data_length+testing_data_length,:]\n",
    "print(testing_data_for_plotting.shape)\n",
    "testing_data_for_plotting.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testing_data_for_plotting.shape)\n",
    "print(testing_targets.shape)\n",
    "print(deep_lstm_model_predictions.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "actual_pm25_vs_predicted_pm25_dataframe = pd.DataFrame({'TimeStamp':testing_data_for_plotting['TimeStamp'].values, \n",
    "                           'Actual PM2.5':testing_targets.ravel(), 'Predicted PM2.5': deep_lstm_model_predictions.ravel()})\n",
    "\n",
    "\n",
    "actual_pm25_vs_predicted_pm25_dataframe[\"TimeStamp\"] = pd.to_datetime(actual_pm25_vs_predicted_pm25_dataframe[\"TimeStamp\"])\n",
    "actual_pm25_vs_predicted_pm25_dataframe = actual_pm25_vs_predicted_pm25_dataframe.set_index('TimeStamp')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "actual_pm25_vs_predicted_pm25_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_lstm_model_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e1NQ6pyMSb4m"
   },
   "outputs": [],
   "source": [
    "fig_deep_lstm_predictions_vs_actual = plt.figure(figsize=(12,6))\n",
    "ax_fig_deep_lstm_predictions_vs_actual = fig_deep_lstm_predictions_vs_actual.add_subplot(111)\n",
    "plt.plot(testing_targets, color = 'red', label = 'Actual PM2.5 Values')\n",
    "plt.plot(deep_lstm_model_predictions, color = 'blue', label = 'Predicted PM2.5 Values')\n",
    "plt.title('Predicted PM2.5  Vs Actual PM2.5 ')\n",
    "plt.xlabel('PM2.5 Records')\n",
    "plt.ylabel('PM2.5 Values')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "fig_deep_lstm_predictions_vs_actual.savefig(os.path.join(filepath, 'deep_lstm_model_prediction_vs_actual.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SAro3NFG2XKh",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "sns.set_style('ticks')\n",
    "sns.set_palette('dark')\n",
    "fig_deep_lstm_predictions_vs_actual_scatter = plt.figure(figsize=(8,6))\n",
    "ax_fig_deep_lstm_predictions_vs_actual_scatter = fig_deep_lstm_predictions_vs_actual_scatter.add_subplot(111)\n",
    "ax = ax_fig_deep_lstm_predictions_vs_actual_scatter\n",
    "# we are going to use y_test, y_test_pred\n",
    "ax.scatter(testing_targets, deep_lstm_model_predictions, alpha=.3)\n",
    "\n",
    "ax.set(xlabel='Actual Values', \n",
    "       ylabel='Predictions',\n",
    "       title='PM2.5 Predictions vs Actual Values');\n",
    "\n",
    "fig_deep_lstm_predictions_vs_actual_scatter.savefig(os.path.join(filepath, 'deep_lstm_model_predictions_vs_actual_values_scatter.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5lryEQH12XKn"
   },
   "source": [
    "### saving results to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2EDwleDm2XLC"
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(filepath, \"results_summary.txt\"), \"w+\") as text_file:\n",
    "        print(\"SVR RMSE : {}\\n SVR MAE : {} \\n Basic LSTM RMSE: {} \\n Basic LSTM MAE: {} \\n Basic LSTM Evaluation Results: {} \\n Deep LSTM RMSE : {} \\n Deep LSTM MAE: {} \\n Deep LSTM Evaluation Results: {}, \\n metrics {}\"\n",
    "              .format(svr_rmse.round(2),svr_mae.round(2),  basic_lstm_rmse.round(2), basic_lstm_mae.round(2), basic_lstm_model_evaluation,\n",
    "                      deep_lstm_rmse.round(2), deep_lstm_mae.round(2),  deep_lstm_model_evaluation, model.metrics_names ), file=text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kTcRwaN42XLT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "air_quality_prediction_experimentation_selected_features.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
